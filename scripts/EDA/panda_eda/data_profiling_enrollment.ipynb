{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68026bf6",
   "metadata": {},
   "source": [
    "# Enrollment EDA (Universal 10-Step Framework)\n",
    "This notebook is reshuffled and rewritten to follow the phase-wise EDA framework from Step 1 to Step 10.\n",
    "\n",
    "How to use:\n",
    "1. Run cells top-to-bottom.\n",
    "2. Do not skip Step 1-4.\n",
    "3. Use advanced cells after core checks pass.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d6b37b",
   "metadata": {},
   "source": [
    "## STEP 1 ? Understand Business Context\n",
    "**Business meaning**\n",
    "- One row represents enrollment counts for one location and date.\n",
    "- Business event: Aadhaar enrollment activity captured by age bucket.\n",
    "- Measured values: `age_0_5`, `age_5_17`, `age_18_greater`.\n",
    "- Decisions supported: trend tracking, quality governance, regional planning.\n",
    "\n",
    "**Beginner goal**\n",
    "- Understand what this table means before coding.\n",
    "\n",
    "**Advanced goal**\n",
    "- Translate business meaning into target grain and quality contracts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "06118433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date          state          district  pincode  age_0_5  age_5_17  \\\n",
      "0  02-03-2025      Meghalaya  East Khasi Hills   793121       11        61   \n",
      "1  09-03-2025      Karnataka   Bengaluru Urban   560043       14        33   \n",
      "2  09-03-2025  Uttar Pradesh      Kanpur Nagar   208001       29        82   \n",
      "3  09-03-2025  Uttar Pradesh           Aligarh   202133       62        29   \n",
      "4  09-03-2025      Karnataka   Bengaluru Urban   560016       14        16   \n",
      "\n",
      "   age_18_greater  \n",
      "0              37  \n",
      "1              39  \n",
      "2              12  \n",
      "3              15  \n",
      "4              21  \n",
      "         date           state  district  pincode  age_0_5  age_5_17  \\\n",
      "0  26-10-2025  Andhra Pradesh  Nalgonda   508004        0         1   \n",
      "1  26-10-2025  Andhra Pradesh  Nalgonda   508238        1         0   \n",
      "2  26-10-2025  Andhra Pradesh  Nalgonda   508278        1         0   \n",
      "3  26-10-2025  Andhra Pradesh   Nandyal   518432        0         1   \n",
      "4  26-10-2025  Andhra Pradesh   Nandyal   518543        1         0   \n",
      "\n",
      "   age_18_greater  \n",
      "0               0  \n",
      "1               0  \n",
      "2               0  \n",
      "3               0  \n",
      "4               0  \n",
      "         date      state district  pincode  age_0_5  age_5_17  age_18_greater\n",
      "0  31-12-2025  Karnataka    Bidar   585330        2         3               0\n",
      "1  31-12-2025  Karnataka    Bidar   585402        6         0               0\n",
      "2  31-12-2025  Karnataka    Bidar   585413        1         0               0\n",
      "3  31-12-2025  Karnataka    Bidar   585418        1         2               0\n",
      "4  31-12-2025  Karnataka    Bidar   585421        4         3               0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "enrolment1 = pd.read_csv(r'C:\\Users\\Atul bhardwaj\\OneDrive\\Desktop\\coding 2 year\\IdentityLakehouse\\data\\api_data_aadhar_enrolment\\api_data_aadhar_enrolment\\api_data_aadhar_enrolment_0_500000.csv')\n",
    "enrolment2 = pd.read_csv(r'C:\\Users\\Atul bhardwaj\\OneDrive\\Desktop\\coding 2 year\\IdentityLakehouse\\data\\api_data_aadhar_enrolment\\api_data_aadhar_enrolment\\api_data_aadhar_enrolment_500000_1000000.csv')\n",
    "enrolment3= pd.read_csv(r'C:\\Users\\Atul bhardwaj\\OneDrive\\Desktop\\coding 2 year\\IdentityLakehouse\\data\\api_data_aadhar_enrolment\\api_data_aadhar_enrolment\\api_data_aadhar_enrolment_1000000_1006029.csv')\n",
    "\n",
    "\n",
    "\n",
    "print(enrolment1.head())\n",
    "print(enrolment2.head())\n",
    "print(enrolment3.head())   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "988848a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enrollment path: C:\\Users\\Atul bhardwaj\\OneDrive\\Desktop\\coding 2 year\\IdentityLakehouse\\scripts\\EDA\\panda_eda\\data\\data_aadhar_enrollment_full.csv\n",
      "Rows, Cols: (1006029, 7)\n"
     ]
    }
   ],
   "source": [
    "# Aim: Set project paths and load Enrollment base table.\n",
    "# Expected Output: data_aadhar_enrollment_full loaded with valid shape and columns.\n",
    "# What You Get: A stable base dataframe for all EDA steps.\n",
    "# Data Engineer Learning: Always isolate path logic to make notebooks portable.\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "enrollment_path = Path(r\"C:\\Users\\Atul bhardwaj\\OneDrive\\Desktop\\coding 2 year\\IdentityLakehouse\\scripts\\EDA\\panda_eda\\data\\data_aadhar_enrollment_full.csv\")\n",
    "\n",
    "if not enrollment_path.exists():\n",
    "    raise FileNotFoundError(f\"Missing enrollment file: {enrollment_path}\")\n",
    "\n",
    "data_aadhar_enrollment_full = pd.read_csv(enrollment_path)\n",
    "\n",
    "print(\"Enrollment path:\", enrollment_path)\n",
    "print(\"Rows, Cols:\", data_aadhar_enrollment_full.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "1761e9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>row_definition</td>\n",
       "      <td>Enrollment counts for one date-state-district-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business_event</td>\n",
       "      <td>Aadhaar enrollment activity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>measures</td>\n",
       "      <td>age_0_5, age_5_17, age_18_greater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>decision_support</td>\n",
       "      <td>Trend monitoring, data quality controls, geogr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              field                                              value\n",
       "0    row_definition  Enrollment counts for one date-state-district-...\n",
       "1    business_event                        Aadhaar enrollment activity\n",
       "2          measures                  age_0_5, age_5_17, age_18_greater\n",
       "3  decision_support  Trend monitoring, data quality controls, geogr..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Record Step-1 business context in a machine-readable table.\n",
    "# Expected Output: One small table summarizing business definition.\n",
    "# What You Get: Documentation artifact you can show in interviews/reviews.\n",
    "# Data Engineer Learning: Good EDA includes explicit semantic documentation.\n",
    "\n",
    "business_context = pd.DataFrame([\n",
    "    {'field': 'row_definition', 'value': 'Enrollment counts for one date-state-district-pincode record'},\n",
    "    {'field': 'business_event', 'value': 'Aadhaar enrollment activity'},\n",
    "    {'field': 'measures', 'value': 'age_0_5, age_5_17, age_18_greater'},\n",
    "    {'field': 'decision_support', 'value': 'Trend monitoring, data quality controls, geographic planning'},\n",
    "])\n",
    "\n",
    "display(business_context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3c4b2f",
   "metadata": {},
   "source": [
    "## STEP 2 ? Structural Profiling\n",
    "Check structure before transformations:\n",
    "- row count, column count\n",
    "- data types\n",
    "- sample records\n",
    "- basic stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146194d6",
   "metadata": {},
   "source": [
    "### Integrated 63-Step Cells For This Section\n",
    "Included steps: 1, 2, 3, 4, 5, 6, 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d24c3e",
   "metadata": {},
   "source": [
    "#### Integrated Step 3 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd074b4",
   "metadata": {},
   "source": [
    "#### Integrated Step 4 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "629acb49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>age_0_5</th>\n",
       "      <th>age_5_17</th>\n",
       "      <th>age_18_greater</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02-03-2025</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>East Khasi Hills</td>\n",
       "      <td>793121</td>\n",
       "      <td>11</td>\n",
       "      <td>61</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bengaluru Urban</td>\n",
       "      <td>560043</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Kanpur Nagar</td>\n",
       "      <td>208001</td>\n",
       "      <td>29</td>\n",
       "      <td>82</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Aligarh</td>\n",
       "      <td>202133</td>\n",
       "      <td>62</td>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bengaluru Urban</td>\n",
       "      <td>560016</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>Sitamarhi</td>\n",
       "      <td>843331</td>\n",
       "      <td>20</td>\n",
       "      <td>49</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>Sitamarhi</td>\n",
       "      <td>843330</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Bahraich</td>\n",
       "      <td>271865</td>\n",
       "      <td>26</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Firozabad</td>\n",
       "      <td>283204</td>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>Purbi Champaran</td>\n",
       "      <td>845418</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date          state          district  pincode  age_0_5  age_5_17  \\\n",
       "0  02-03-2025      Meghalaya  East Khasi Hills   793121       11        61   \n",
       "1  09-03-2025      Karnataka   Bengaluru Urban   560043       14        33   \n",
       "2  09-03-2025  Uttar Pradesh      Kanpur Nagar   208001       29        82   \n",
       "3  09-03-2025  Uttar Pradesh           Aligarh   202133       62        29   \n",
       "4  09-03-2025      Karnataka   Bengaluru Urban   560016       14        16   \n",
       "5  09-03-2025          Bihar         Sitamarhi   843331       20        49   \n",
       "6  09-03-2025          Bihar         Sitamarhi   843330       23        24   \n",
       "7  09-03-2025  Uttar Pradesh          Bahraich   271865       26        60   \n",
       "8  09-03-2025  Uttar Pradesh         Firozabad   283204       28        26   \n",
       "9  09-03-2025          Bihar   Purbi Champaran   845418       30        48   \n",
       "\n",
       "   age_18_greater  \n",
       "0              37  \n",
       "1              39  \n",
       "2              12  \n",
       "3              15  \n",
       "4              21  \n",
       "5              12  \n",
       "6              42  \n",
       "7              14  \n",
       "8              10  \n",
       "9              10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Preview first rows\n",
    "# Expected Output: Valid output for Step 4 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 4 improves trust in downstream analytics.\n",
    "\n",
    "display(data_aadhar_enrollment_full.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3577726d",
   "metadata": {},
   "source": [
    "#### Integrated Step 5 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b92ec47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>age_0_5</th>\n",
       "      <th>age_5_17</th>\n",
       "      <th>age_18_greater</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1006029</td>\n",
       "      <td>1006029</td>\n",
       "      <td>1006029</td>\n",
       "      <td>1.006029e+06</td>\n",
       "      <td>1.006029e+06</td>\n",
       "      <td>1.006029e+06</td>\n",
       "      <td>1.006029e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>92</td>\n",
       "      <td>55</td>\n",
       "      <td>985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>15-12-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Pune</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>19426</td>\n",
       "      <td>110369</td>\n",
       "      <td>6663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.186415e+05</td>\n",
       "      <td>3.525709e+00</td>\n",
       "      <td>1.710074e+00</td>\n",
       "      <td>1.673441e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.056360e+05</td>\n",
       "      <td>1.753851e+01</td>\n",
       "      <td>1.436963e+01</td>\n",
       "      <td>3.220525e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.636410e+05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.174170e+05</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.001040e+05</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.554560e+05</td>\n",
       "      <td>2.688000e+03</td>\n",
       "      <td>1.812000e+03</td>\n",
       "      <td>8.550000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date          state district       pincode       age_0_5  \\\n",
       "count      1006029        1006029  1006029  1.006029e+06  1.006029e+06   \n",
       "unique          92             55      985           NaN           NaN   \n",
       "top     15-12-2025  Uttar Pradesh     Pune           NaN           NaN   \n",
       "freq         19426         110369     6663           NaN           NaN   \n",
       "mean           NaN            NaN      NaN  5.186415e+05  3.525709e+00   \n",
       "std            NaN            NaN      NaN  2.056360e+05  1.753851e+01   \n",
       "min            NaN            NaN      NaN  1.000000e+05  0.000000e+00   \n",
       "25%            NaN            NaN      NaN  3.636410e+05  1.000000e+00   \n",
       "50%            NaN            NaN      NaN  5.174170e+05  2.000000e+00   \n",
       "75%            NaN            NaN      NaN  7.001040e+05  3.000000e+00   \n",
       "max            NaN            NaN      NaN  8.554560e+05  2.688000e+03   \n",
       "\n",
       "            age_5_17  age_18_greater  \n",
       "count   1.006029e+06    1.006029e+06  \n",
       "unique           NaN             NaN  \n",
       "top              NaN             NaN  \n",
       "freq             NaN             NaN  \n",
       "mean    1.710074e+00    1.673441e-01  \n",
       "std     1.436963e+01    3.220525e+00  \n",
       "min     0.000000e+00    0.000000e+00  \n",
       "25%     0.000000e+00    0.000000e+00  \n",
       "50%     0.000000e+00    0.000000e+00  \n",
       "75%     1.000000e+00    0.000000e+00  \n",
       "max     1.812000e+03    8.550000e+02  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Inspect numeric summary\n",
    "# Expected Output: Valid output for Step 5 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 5 improves trust in downstream analytics.\n",
    "\n",
    "display(data_aadhar_enrollment_full.describe(include='all'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c78536",
   "metadata": {},
   "source": [
    "#### Integrated Step 6 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "328d5cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (1006029, 7)\n"
     ]
    }
   ],
   "source": [
    "# Aim: Inspect table size\n",
    "# Expected Output: Valid output for Step 6 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 6 improves trust in downstream analytics.\n",
    "\n",
    "print('shape', data_aadhar_enrollment_full.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae502969",
   "metadata": {},
   "source": [
    "#### Integrated Step 7 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "87a4cfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_states 55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                           100000\n",
       "1                        Andaman & Nicobar Islands\n",
       "2                      Andaman and Nicobar Islands\n",
       "3                                   Andhra Pradesh\n",
       "4                                Arunachal Pradesh\n",
       "5                                            Assam\n",
       "6                                            Bihar\n",
       "7                                       Chandigarh\n",
       "8                                     Chhattisgarh\n",
       "9                             Dadra & Nagar Haveli\n",
       "10                          Dadra and Nagar Haveli\n",
       "11        Dadra and Nagar Haveli and Daman and Diu\n",
       "12                                     Daman & Diu\n",
       "13                                   Daman and Diu\n",
       "14                                           Delhi\n",
       "15                                             Goa\n",
       "16                                         Gujarat\n",
       "17                                         Haryana\n",
       "18                                Himachal Pradesh\n",
       "19                                 Jammu & Kashmir\n",
       "20                               Jammu And Kashmir\n",
       "21                               Jammu and Kashmir\n",
       "22                                       Jharkhand\n",
       "23                                       Karnataka\n",
       "24                                          Kerala\n",
       "25                                          Ladakh\n",
       "26                                     Lakshadweep\n",
       "27                                  Madhya Pradesh\n",
       "28                                     Maharashtra\n",
       "29                                         Manipur\n",
       "30                                       Meghalaya\n",
       "31                                         Mizoram\n",
       "32                                        Nagaland\n",
       "33                                          ODISHA\n",
       "34                                          Odisha\n",
       "35                                          Orissa\n",
       "36                                     Pondicherry\n",
       "37                                      Puducherry\n",
       "38                                          Punjab\n",
       "39                                       Rajasthan\n",
       "40                                          Sikkim\n",
       "41                                      Tamil Nadu\n",
       "42                                       Telangana\n",
       "43    The Dadra And Nagar Haveli And Daman And Diu\n",
       "44                                         Tripura\n",
       "45                                   Uttar Pradesh\n",
       "46                                     Uttarakhand\n",
       "47                                     WEST BENGAL\n",
       "48                                      WESTBENGAL\n",
       "49                                    West  Bengal\n",
       "50                                     West Bangal\n",
       "51                                     West Bengal\n",
       "52                                     West bengal\n",
       "53                                      Westbengal\n",
       "54                                  andhra pradesh\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Count unique raw states\n",
    "# Expected Output: Valid output for Step 7 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 7 improves trust in downstream analytics.\n",
    "\n",
    "print('unique_states', data_aadhar_enrollment_full['state'].nunique()); display(pd.Series(sorted(data_aadhar_enrollment_full['state'].dropna().astype(str).unique())).head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9019c013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1006029, 7)\n",
      "\n",
      "Columns:\n",
      "['date', 'state', 'district', 'pincode', 'age_0_5', 'age_5_17', 'age_18_greater']\n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1006029 entries, 0 to 1006028\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count    Dtype \n",
      "---  ------          --------------    ----- \n",
      " 0   date            1006029 non-null  object\n",
      " 1   state           1006029 non-null  object\n",
      " 2   district        1006029 non-null  object\n",
      " 3   pincode         1006029 non-null  int64 \n",
      " 4   age_0_5         1006029 non-null  int64 \n",
      " 5   age_5_17        1006029 non-null  int64 \n",
      " 6   age_18_greater  1006029 non-null  int64 \n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 53.7+ MB\n",
      "None\n",
      "\n",
      "Sample rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>age_0_5</th>\n",
       "      <th>age_5_17</th>\n",
       "      <th>age_18_greater</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02-03-2025</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>East Khasi Hills</td>\n",
       "      <td>793121</td>\n",
       "      <td>11</td>\n",
       "      <td>61</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bengaluru Urban</td>\n",
       "      <td>560043</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Kanpur Nagar</td>\n",
       "      <td>208001</td>\n",
       "      <td>29</td>\n",
       "      <td>82</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Aligarh</td>\n",
       "      <td>202133</td>\n",
       "      <td>62</td>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bengaluru Urban</td>\n",
       "      <td>560016</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>Sitamarhi</td>\n",
       "      <td>843331</td>\n",
       "      <td>20</td>\n",
       "      <td>49</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>Sitamarhi</td>\n",
       "      <td>843330</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Bahraich</td>\n",
       "      <td>271865</td>\n",
       "      <td>26</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Firozabad</td>\n",
       "      <td>283204</td>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>Purbi Champaran</td>\n",
       "      <td>845418</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date          state          district  pincode  age_0_5  age_5_17  \\\n",
       "0  02-03-2025      Meghalaya  East Khasi Hills   793121       11        61   \n",
       "1  09-03-2025      Karnataka   Bengaluru Urban   560043       14        33   \n",
       "2  09-03-2025  Uttar Pradesh      Kanpur Nagar   208001       29        82   \n",
       "3  09-03-2025  Uttar Pradesh           Aligarh   202133       62        29   \n",
       "4  09-03-2025      Karnataka   Bengaluru Urban   560016       14        16   \n",
       "5  09-03-2025          Bihar         Sitamarhi   843331       20        49   \n",
       "6  09-03-2025          Bihar         Sitamarhi   843330       23        24   \n",
       "7  09-03-2025  Uttar Pradesh          Bahraich   271865       26        60   \n",
       "8  09-03-2025  Uttar Pradesh         Firozabad   283204       28        26   \n",
       "9  09-03-2025          Bihar   Purbi Champaran   845418       30        48   \n",
       "\n",
       "   age_18_greater  \n",
       "0              37  \n",
       "1              39  \n",
       "2              12  \n",
       "3              15  \n",
       "4              21  \n",
       "5              12  \n",
       "6              42  \n",
       "7              14  \n",
       "8              10  \n",
       "9              10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Inspect table structure and schema health.\n",
    "# Expected Output: shape, columns list, dtypes summary, sample rows.\n",
    "# What You Get: Structural baseline to detect schema drift.\n",
    "# Data Engineer Learning: Structure-first profiling prevents downstream surprises.\n",
    "\n",
    "print('Shape:', data_aadhar_enrollment_full.shape)\n",
    "print('\\nColumns:')\n",
    "print(list(data_aadhar_enrollment_full.columns))\n",
    "print('\\nInfo:')\n",
    "print(data_aadhar_enrollment_full.info())\n",
    "print('\\nSample rows:')\n",
    "display(data_aadhar_enrollment_full.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "21722033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>age_0_5</th>\n",
       "      <th>age_5_17</th>\n",
       "      <th>age_18_greater</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1006029</td>\n",
       "      <td>1006029</td>\n",
       "      <td>1006029</td>\n",
       "      <td>1.006029e+06</td>\n",
       "      <td>1.006029e+06</td>\n",
       "      <td>1.006029e+06</td>\n",
       "      <td>1.006029e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>92</td>\n",
       "      <td>55</td>\n",
       "      <td>985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>15-12-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Pune</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>19426</td>\n",
       "      <td>110369</td>\n",
       "      <td>6663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.186415e+05</td>\n",
       "      <td>3.525709e+00</td>\n",
       "      <td>1.710074e+00</td>\n",
       "      <td>1.673441e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.056360e+05</td>\n",
       "      <td>1.753851e+01</td>\n",
       "      <td>1.436963e+01</td>\n",
       "      <td>3.220525e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.636410e+05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.174170e+05</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.001040e+05</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.554560e+05</td>\n",
       "      <td>2.688000e+03</td>\n",
       "      <td>1.812000e+03</td>\n",
       "      <td>8.550000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date          state district       pincode       age_0_5  \\\n",
       "count      1006029        1006029  1006029  1.006029e+06  1.006029e+06   \n",
       "unique          92             55      985           NaN           NaN   \n",
       "top     15-12-2025  Uttar Pradesh     Pune           NaN           NaN   \n",
       "freq         19426         110369     6663           NaN           NaN   \n",
       "mean           NaN            NaN      NaN  5.186415e+05  3.525709e+00   \n",
       "std            NaN            NaN      NaN  2.056360e+05  1.753851e+01   \n",
       "min            NaN            NaN      NaN  1.000000e+05  0.000000e+00   \n",
       "25%            NaN            NaN      NaN  3.636410e+05  1.000000e+00   \n",
       "50%            NaN            NaN      NaN  5.174170e+05  2.000000e+00   \n",
       "75%            NaN            NaN      NaN  7.001040e+05  3.000000e+00   \n",
       "max            NaN            NaN      NaN  8.554560e+05  2.688000e+03   \n",
       "\n",
       "            age_5_17  age_18_greater  \n",
       "count   1.006029e+06    1.006029e+06  \n",
       "unique           NaN             NaN  \n",
       "top              NaN             NaN  \n",
       "freq             NaN             NaN  \n",
       "mean    1.710074e+00    1.673441e-01  \n",
       "std     1.436963e+01    3.220525e+00  \n",
       "min     0.000000e+00    0.000000e+00  \n",
       "25%     0.000000e+00    0.000000e+00  \n",
       "50%     0.000000e+00    0.000000e+00  \n",
       "75%     1.000000e+00    0.000000e+00  \n",
       "max     1.812000e+03    8.550000e+02  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Generate numeric profile for quick sanity checks.\n",
    "# Expected Output: describe() summary for numeric columns.\n",
    "# What You Get: Range, spread, and count overview.\n",
    "# Data Engineer Learning: Numeric profiling quickly exposes impossible values.\n",
    "\n",
    "display(data_aadhar_enrollment_full.describe(include='all'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895a60c9",
   "metadata": {},
   "source": [
    "## STEP 3 ? Grain Identification (Most Important)\n",
    "Natural key hypothesis:\n",
    "- `(date, state, district, pincode)`\n",
    "\n",
    "If this is not clear, modeling fails.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365d5e87",
   "metadata": {},
   "source": [
    "### Integrated 63-Step Cells For This Section\n",
    "Included steps: 8, 9, 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516b71c9",
   "metadata": {},
   "source": [
    "#### Integrated Step 8 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "641ca0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dup_key 22957\n"
     ]
    }
   ],
   "source": [
    "# Aim: Count key-based duplicates\n",
    "# Expected Output: Valid output for Step 8 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 8 improves trust in downstream analytics.\n",
    "\n",
    "natural_key=['date','state','district','pincode']; print('dup_key', int(data_aadhar_enrollment_full.duplicated(subset=natural_key).sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf92020a",
   "metadata": {},
   "source": [
    "#### Integrated Step 9 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a91272fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dup_group_rows 45914\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>age_0_5</th>\n",
       "      <th>age_5_17</th>\n",
       "      <th>age_18_greater</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>588088</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786007</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590380</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786007</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588089</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786008</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590381</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786008</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588090</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590382</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588091</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786184</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590383</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786184</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588092</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786610</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590384</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786610</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588093</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786613</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590385</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786613</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588094</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Goalpara</td>\n",
       "      <td>783121</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590386</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Goalpara</td>\n",
       "      <td>783121</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588095</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Goalpara</td>\n",
       "      <td>783124</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590387</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Goalpara</td>\n",
       "      <td>783124</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588096</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Goalpara</td>\n",
       "      <td>783129</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590388</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Goalpara</td>\n",
       "      <td>783129</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588097</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Golaghat</td>\n",
       "      <td>785613</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590389</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Golaghat</td>\n",
       "      <td>785613</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588098</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Golaghat</td>\n",
       "      <td>785615</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590390</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Golaghat</td>\n",
       "      <td>785615</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588099</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Golaghat</td>\n",
       "      <td>785618</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590391</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Golaghat</td>\n",
       "      <td>785618</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588100</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Golaghat</td>\n",
       "      <td>785622</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590392</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Golaghat</td>\n",
       "      <td>785622</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588101</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Hailakandi</td>\n",
       "      <td>788117</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590393</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Hailakandi</td>\n",
       "      <td>788117</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588102</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Hailakandi</td>\n",
       "      <td>788161</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590394</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Hailakandi</td>\n",
       "      <td>788161</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  state    district  pincode  age_0_5  age_5_17  \\\n",
       "588088  02-11-2025  Assam   Dibrugarh   786007        2         0   \n",
       "590380  02-11-2025  Assam   Dibrugarh   786007        2         0   \n",
       "588089  02-11-2025  Assam   Dibrugarh   786008        3         0   \n",
       "590381  02-11-2025  Assam   Dibrugarh   786008        3         0   \n",
       "588090  02-11-2025  Assam   Dibrugarh   786012        1         0   \n",
       "590382  02-11-2025  Assam   Dibrugarh   786012        1         0   \n",
       "588091  02-11-2025  Assam   Dibrugarh   786184        5         0   \n",
       "590383  02-11-2025  Assam   Dibrugarh   786184        5         0   \n",
       "588092  02-11-2025  Assam   Dibrugarh   786610        3         2   \n",
       "590384  02-11-2025  Assam   Dibrugarh   786610        3         2   \n",
       "588093  02-11-2025  Assam   Dibrugarh   786613        2         0   \n",
       "590385  02-11-2025  Assam   Dibrugarh   786613        2         0   \n",
       "588094  02-11-2025  Assam    Goalpara   783121        2         2   \n",
       "590386  02-11-2025  Assam    Goalpara   783121        2         2   \n",
       "588095  02-11-2025  Assam    Goalpara   783124        1         0   \n",
       "590387  02-11-2025  Assam    Goalpara   783124        1         0   \n",
       "588096  02-11-2025  Assam    Goalpara   783129        6         7   \n",
       "590388  02-11-2025  Assam    Goalpara   783129        6         7   \n",
       "588097  02-11-2025  Assam    Golaghat   785613        3         1   \n",
       "590389  02-11-2025  Assam    Golaghat   785613        3         1   \n",
       "588098  02-11-2025  Assam    Golaghat   785615        2         1   \n",
       "590390  02-11-2025  Assam    Golaghat   785615        2         1   \n",
       "588099  02-11-2025  Assam    Golaghat   785618        1         0   \n",
       "590391  02-11-2025  Assam    Golaghat   785618        1         0   \n",
       "588100  02-11-2025  Assam    Golaghat   785622        1         1   \n",
       "590392  02-11-2025  Assam    Golaghat   785622        1         1   \n",
       "588101  02-11-2025  Assam  Hailakandi   788117        0         2   \n",
       "590393  02-11-2025  Assam  Hailakandi   788117        0         2   \n",
       "588102  02-11-2025  Assam  Hailakandi   788161       17         1   \n",
       "590394  02-11-2025  Assam  Hailakandi   788161       17         1   \n",
       "\n",
       "        age_18_greater  \n",
       "588088               0  \n",
       "590380               0  \n",
       "588089               0  \n",
       "590381               0  \n",
       "588090               0  \n",
       "590382               0  \n",
       "588091               0  \n",
       "590383               0  \n",
       "588092               0  \n",
       "590384               0  \n",
       "588093               0  \n",
       "590385               0  \n",
       "588094               0  \n",
       "590386               0  \n",
       "588095               0  \n",
       "590387               0  \n",
       "588096               0  \n",
       "590388               0  \n",
       "588097               0  \n",
       "590389               0  \n",
       "588098               0  \n",
       "590390               0  \n",
       "588099               0  \n",
       "590391               0  \n",
       "588100               0  \n",
       "590392               0  \n",
       "588101               0  \n",
       "590393               0  \n",
       "588102               0  \n",
       "590394               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: View duplicate groups in detail\n",
    "# Expected Output: Valid output for Step 9 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 9 improves trust in downstream analytics.\n",
    "\n",
    "dup_examples = data_aadhar_enrollment_full[data_aadhar_enrollment_full.duplicated(subset=natural_key, keep=False)].sort_values(natural_key); print('dup_group_rows', len(dup_examples)); display(dup_examples.head(30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fc5791",
   "metadata": {},
   "source": [
    "#### Integrated Step 10 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a1beb5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dup_full 22957\n"
     ]
    }
   ],
   "source": [
    "# Aim: Count exact row duplicates\n",
    "# Expected Output: Valid output for Step 10 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 10 improves trust in downstream analytics.\n",
    "\n",
    "dup_full = int(data_aadhar_enrollment_full.duplicated().sum()); print('dup_full', dup_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b38db58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Key: ['date', 'state', 'district', 'pincode']\n",
      "Duplicate rows at natural key: 22957\n"
     ]
    }
   ],
   "source": [
    "# Aim: Validate natural grain and key uniqueness.\n",
    "# Expected Output: duplicate count at candidate natural key.\n",
    "# What You Get: Evidence that (date,state,district,pincode) is the row grain.\n",
    "# Data Engineer Learning: Grain must be validated before any aggregation/modeling.\n",
    "\n",
    "natural_key = ['date', 'state', 'district', 'pincode']\n",
    "\n",
    "dup_grain_count = int(data_aadhar_enrollment_full.duplicated(subset=natural_key).sum())\n",
    "print('Natural Key:', natural_key)\n",
    "print('Duplicate rows at natural key:', dup_grain_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "20743364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate sample size: 45914\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>age_0_5</th>\n",
       "      <th>age_5_17</th>\n",
       "      <th>age_18_greater</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>588088</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786007</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590380</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786007</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588089</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786008</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590381</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786008</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588090</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590382</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588091</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786184</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590383</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786184</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588092</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786610</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590384</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786610</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588093</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786613</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590385</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>786613</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588094</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Goalpara</td>\n",
       "      <td>783121</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590386</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Goalpara</td>\n",
       "      <td>783121</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588095</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Goalpara</td>\n",
       "      <td>783124</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590387</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Goalpara</td>\n",
       "      <td>783124</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588096</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Goalpara</td>\n",
       "      <td>783129</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590388</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Goalpara</td>\n",
       "      <td>783129</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588097</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Golaghat</td>\n",
       "      <td>785613</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590389</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Golaghat</td>\n",
       "      <td>785613</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588098</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Golaghat</td>\n",
       "      <td>785615</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590390</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Golaghat</td>\n",
       "      <td>785615</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588099</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Golaghat</td>\n",
       "      <td>785618</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590391</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Golaghat</td>\n",
       "      <td>785618</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588100</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Golaghat</td>\n",
       "      <td>785622</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590392</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Golaghat</td>\n",
       "      <td>785622</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588101</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Hailakandi</td>\n",
       "      <td>788117</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590393</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Hailakandi</td>\n",
       "      <td>788117</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588102</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Hailakandi</td>\n",
       "      <td>788161</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590394</th>\n",
       "      <td>02-11-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Hailakandi</td>\n",
       "      <td>788161</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  state    district  pincode  age_0_5  age_5_17  \\\n",
       "588088  02-11-2025  Assam   Dibrugarh   786007        2         0   \n",
       "590380  02-11-2025  Assam   Dibrugarh   786007        2         0   \n",
       "588089  02-11-2025  Assam   Dibrugarh   786008        3         0   \n",
       "590381  02-11-2025  Assam   Dibrugarh   786008        3         0   \n",
       "588090  02-11-2025  Assam   Dibrugarh   786012        1         0   \n",
       "590382  02-11-2025  Assam   Dibrugarh   786012        1         0   \n",
       "588091  02-11-2025  Assam   Dibrugarh   786184        5         0   \n",
       "590383  02-11-2025  Assam   Dibrugarh   786184        5         0   \n",
       "588092  02-11-2025  Assam   Dibrugarh   786610        3         2   \n",
       "590384  02-11-2025  Assam   Dibrugarh   786610        3         2   \n",
       "588093  02-11-2025  Assam   Dibrugarh   786613        2         0   \n",
       "590385  02-11-2025  Assam   Dibrugarh   786613        2         0   \n",
       "588094  02-11-2025  Assam    Goalpara   783121        2         2   \n",
       "590386  02-11-2025  Assam    Goalpara   783121        2         2   \n",
       "588095  02-11-2025  Assam    Goalpara   783124        1         0   \n",
       "590387  02-11-2025  Assam    Goalpara   783124        1         0   \n",
       "588096  02-11-2025  Assam    Goalpara   783129        6         7   \n",
       "590388  02-11-2025  Assam    Goalpara   783129        6         7   \n",
       "588097  02-11-2025  Assam    Golaghat   785613        3         1   \n",
       "590389  02-11-2025  Assam    Golaghat   785613        3         1   \n",
       "588098  02-11-2025  Assam    Golaghat   785615        2         1   \n",
       "590390  02-11-2025  Assam    Golaghat   785615        2         1   \n",
       "588099  02-11-2025  Assam    Golaghat   785618        1         0   \n",
       "590391  02-11-2025  Assam    Golaghat   785618        1         0   \n",
       "588100  02-11-2025  Assam    Golaghat   785622        1         1   \n",
       "590392  02-11-2025  Assam    Golaghat   785622        1         1   \n",
       "588101  02-11-2025  Assam  Hailakandi   788117        0         2   \n",
       "590393  02-11-2025  Assam  Hailakandi   788117        0         2   \n",
       "588102  02-11-2025  Assam  Hailakandi   788161       17         1   \n",
       "590394  02-11-2025  Assam  Hailakandi   788161       17         1   \n",
       "\n",
       "        age_18_greater  \n",
       "588088               0  \n",
       "590380               0  \n",
       "588089               0  \n",
       "590381               0  \n",
       "588090               0  \n",
       "590382               0  \n",
       "588091               0  \n",
       "590383               0  \n",
       "588092               0  \n",
       "590384               0  \n",
       "588093               0  \n",
       "590385               0  \n",
       "588094               0  \n",
       "590386               0  \n",
       "588095               0  \n",
       "590387               0  \n",
       "588096               0  \n",
       "590388               0  \n",
       "588097               0  \n",
       "590389               0  \n",
       "588098               0  \n",
       "590390               0  \n",
       "588099               0  \n",
       "590391               0  \n",
       "588100               0  \n",
       "590392               0  \n",
       "588101               0  \n",
       "590393               0  \n",
       "588102               0  \n",
       "590394               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Show duplicate key examples for root-cause review.\n",
    "# Expected Output: duplicate sample rows sorted by natural key.\n",
    "# What You Get: Concrete records to investigate ingestion or source duplication.\n",
    "# Data Engineer Learning: Always inspect duplicate examples, not only counts.\n",
    "\n",
    "dup_examples = data_aadhar_enrollment_full[\n",
    "    data_aadhar_enrollment_full.duplicated(subset=natural_key, keep=False)\n",
    "].sort_values(natural_key)\n",
    "\n",
    "print('Duplicate sample size:', len(dup_examples))\n",
    "display(dup_examples.head(30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48b65b4",
   "metadata": {},
   "source": [
    "## STEP 4 ? Data Quality Assessment\n",
    "### 4.1 Null Analysis\n",
    "### 4.2 Duplicate Analysis\n",
    "### 4.3 Range Validation\n",
    "### 4.4 Format Issues\n",
    "### 4.5 Outlier Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e761afec",
   "metadata": {},
   "source": [
    "### Integrated 63-Step Cells For This Section\n",
    "Included steps: 11, 12, 13, 14, 15, 16, 17, 41, 42, 43, 44, 45, 46, 47, 53, 54, 55, 56, 57, 58, 59\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57667ab",
   "metadata": {},
   "source": [
    "#### Integrated Step 11 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c94a56d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows_after_dedup 983072\n"
     ]
    }
   ],
   "source": [
    "# Aim: Drop key-based duplicates\n",
    "# Expected Output: Valid output for Step 11 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 11 improves trust in downstream analytics.\n",
    "\n",
    "data_aadhar_enrollment_dedup = data_aadhar_enrollment_full.drop_duplicates(subset=natural_key, keep='first').reset_index(drop=True); print('rows_after_dedup', len(data_aadhar_enrollment_dedup))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f6befb",
   "metadata": {},
   "source": [
    "#### Integrated Step 12 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "668dc371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dup_key_after 0\n"
     ]
    }
   ],
   "source": [
    "# Aim: Re-check duplicates after drop\n",
    "# Expected Output: Valid output for Step 12 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 12 improves trust in downstream analytics.\n",
    "\n",
    "print('dup_key_after', int(data_aadhar_enrollment_dedup.duplicated(subset=natural_key).sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d203928",
   "metadata": {},
   "source": [
    "#### Integrated Step 13 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "90e7bcda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rows_before</td>\n",
       "      <td>1006029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rows_after</td>\n",
       "      <td>983072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>full_dup_before</td>\n",
       "      <td>22957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>key_dup_after</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            metric    value\n",
       "0      rows_before  1006029\n",
       "1       rows_after   983072\n",
       "2  full_dup_before    22957\n",
       "3    key_dup_after        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Document before/after duplicate impact\n",
    "# Expected Output: Valid output for Step 13 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 13 improves trust in downstream analytics.\n",
    "\n",
    "dup_impact = pd.DataFrame([{'metric':'rows_before','value':len(data_aadhar_enrollment_full)},{'metric':'rows_after','value':len(data_aadhar_enrollment_dedup)},{'metric':'full_dup_before','value':dup_full},{'metric':'key_dup_after','value':int(data_aadhar_enrollment_dedup.duplicated(subset=natural_key).sum())}]); display(dup_impact)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9cbcbb",
   "metadata": {},
   "source": [
    "#### Integrated Step 14 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "0f5a469f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-02 00:00:00 2025-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Aim: Check date range\n",
    "# Expected Output: Valid output for Step 14 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 14 improves trust in downstream analytics.\n",
    "\n",
    "tmp_date = pd.to_datetime(data_aadhar_enrollment_dedup['date'], dayfirst=True, errors='coerce'); print(tmp_date.min(), tmp_date.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5df573a",
   "metadata": {},
   "source": [
    "#### Integrated Step 15 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "cfaf1722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null_dates 0\n"
     ]
    }
   ],
   "source": [
    "# Aim: Check null dates\n",
    "# Expected Output: Valid output for Step 15 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 15 improves trust in downstream analytics.\n",
    "\n",
    "print('null_dates', int(pd.to_datetime(data_aadhar_enrollment_dedup['date'], dayfirst=True, errors='coerce').isna().sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fb4dc1",
   "metadata": {},
   "source": [
    "#### Integrated Step 16 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c6dbac67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_states_after_dedup 55\n"
     ]
    }
   ],
   "source": [
    "# Aim: Re-check unique raw states after dedupe\n",
    "# Expected Output: Valid output for Step 16 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 16 improves trust in downstream analytics.\n",
    "\n",
    "print('unique_states_after_dedup', data_aadhar_enrollment_dedup['state'].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256553fe",
   "metadata": {},
   "source": [
    "#### Integrated Step 17 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "173cd9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           100000\n",
       "1                        Andaman & Nicobar Islands\n",
       "2                      Andaman and Nicobar Islands\n",
       "3                                   Andhra Pradesh\n",
       "4                                Arunachal Pradesh\n",
       "5                                            Assam\n",
       "6                                            Bihar\n",
       "7                                       Chandigarh\n",
       "8                                     Chhattisgarh\n",
       "9                             Dadra & Nagar Haveli\n",
       "10                          Dadra and Nagar Haveli\n",
       "11        Dadra and Nagar Haveli and Daman and Diu\n",
       "12                                     Daman & Diu\n",
       "13                                   Daman and Diu\n",
       "14                                           Delhi\n",
       "15                                             Goa\n",
       "16                                         Gujarat\n",
       "17                                         Haryana\n",
       "18                                Himachal Pradesh\n",
       "19                                 Jammu & Kashmir\n",
       "20                               Jammu And Kashmir\n",
       "21                               Jammu and Kashmir\n",
       "22                                       Jharkhand\n",
       "23                                       Karnataka\n",
       "24                                          Kerala\n",
       "25                                          Ladakh\n",
       "26                                     Lakshadweep\n",
       "27                                  Madhya Pradesh\n",
       "28                                     Maharashtra\n",
       "29                                         Manipur\n",
       "30                                       Meghalaya\n",
       "31                                         Mizoram\n",
       "32                                        Nagaland\n",
       "33                                          ODISHA\n",
       "34                                          Odisha\n",
       "35                                          Orissa\n",
       "36                                     Pondicherry\n",
       "37                                      Puducherry\n",
       "38                                          Punjab\n",
       "39                                       Rajasthan\n",
       "40                                          Sikkim\n",
       "41                                      Tamil Nadu\n",
       "42                                       Telangana\n",
       "43    The Dadra And Nagar Haveli And Daman And Diu\n",
       "44                                         Tripura\n",
       "45                                   Uttar Pradesh\n",
       "46                                     Uttarakhand\n",
       "47                                     WEST BENGAL\n",
       "48                                      WESTBENGAL\n",
       "49                                    West  Bengal\n",
       "50                                     West Bangal\n",
       "51                                     West Bengal\n",
       "52                                     West bengal\n",
       "53                                      Westbengal\n",
       "54                                  andhra pradesh\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: List raw state labels\n",
    "# Expected Output: Valid output for Step 17 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 17 improves trust in downstream analytics.\n",
    "\n",
    "display(pd.Series(sorted(data_aadhar_enrollment_dedup['state'].dropna().astype(str).unique())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60523b26",
   "metadata": {},
   "source": [
    "#### Integrated Step 41 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6317b2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eda_enroll_rows 983072\n"
     ]
    }
   ],
   "source": [
    "# Aim: Create eda_enroll working copy\n",
    "# Expected Output: Valid output for Step 41 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 41 improves trust in downstream analytics.\n",
    "\n",
    "eda_enroll = data_aadhar_enrollment_dedup.copy(); print('eda_enroll_rows', len(eda_enroll))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7104ada0",
   "metadata": {},
   "source": [
    "#### Integrated Step 42 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c98611d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null_date_after_parse 0\n"
     ]
    }
   ],
   "source": [
    "# Aim: Convert date to datetime in eda_enroll\n",
    "# Expected Output: Valid output for Step 42 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 42 improves trust in downstream analytics.\n",
    "\n",
    "eda_enroll['date'] = pd.to_datetime(eda_enroll['date'], dayfirst=True, errors='coerce'); print('null_date_after_parse', int(eda_enroll['date'].isna().sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e8dda4",
   "metadata": {},
   "source": [
    "#### Integrated Step 43 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "69238a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_enrollment_created\n"
     ]
    }
   ],
   "source": [
    "# Aim: Create total_enrollment\n",
    "# Expected Output: Valid output for Step 43 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 43 improves trust in downstream analytics.\n",
    "\n",
    "eda_enroll['total_enrollment']=eda_enroll['age_0_5'].fillna(0)+eda_enroll['age_5_17'].fillna(0)+eda_enroll['age_18_greater'].fillna(0); print('total_enrollment_created')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8f8e44",
   "metadata": {},
   "source": [
    "#### Integrated Step 44 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5ff37e",
   "metadata": {},
   "source": [
    "#### Integrated Step 45 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dae5bff",
   "metadata": {},
   "source": [
    "#### Integrated Step 46 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1acefc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>missing_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>state</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>district</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pincode</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age_0_5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>age_5_17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>age_18_greater</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>total_enrollment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             column  missing_count\n",
       "0              date              0\n",
       "1             state              0\n",
       "2          district              0\n",
       "3           pincode              0\n",
       "4           age_0_5              0\n",
       "5          age_5_17              0\n",
       "6    age_18_greater              0\n",
       "7  total_enrollment              0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Missing-value summary by column\n",
    "# Expected Output: Valid output for Step 46 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 46 improves trust in downstream analytics.\n",
    "\n",
    "missing_summary = eda_enroll.isna().sum().reset_index(name='missing_count').rename(columns={'index':'column'}).sort_values('missing_count', ascending=False); display(missing_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f7eda3",
   "metadata": {},
   "source": [
    "#### Integrated Step 47 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "328081c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative_rows 0\n"
     ]
    }
   ],
   "source": [
    "# Aim: Negative-value checks in numeric columns\n",
    "# Expected Output: Valid output for Step 47 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 47 improves trust in downstream analytics.\n",
    "\n",
    "print('negative_rows', int((eda_enroll[['age_0_5','age_5_17','age_18_greater','total_enrollment']] < 0).any(axis=1).sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd015be",
   "metadata": {},
   "source": [
    "#### Integrated Step 53 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ec430526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date              0\n",
       "state             0\n",
       "district          0\n",
       "pincode           0\n",
       "age_0_5           0\n",
       "age_5_17          0\n",
       "age_18_greater    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Null counts on main dataframe\n",
    "# Expected Output: Valid output for Step 53 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 53 improves trust in downstream analytics.\n",
    "\n",
    "display(data_aadhar_enrollment_dedup.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d52d808",
   "metadata": {},
   "source": [
    "#### Integrated Step 54 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3c47d4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                0\n",
       "state               0\n",
       "district            0\n",
       "pincode             0\n",
       "age_0_5             0\n",
       "age_5_17            0\n",
       "age_18_greater      0\n",
       "total_enrollment    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Null counts on eda_enroll\n",
    "# Expected Output: Valid output for Step 54 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 54 improves trust in downstream analytics.\n",
    "\n",
    "display(eda_enroll.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8738aba1",
   "metadata": {},
   "source": [
    "#### Integrated Step 55 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "41dd5a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                0.0\n",
       "state               0.0\n",
       "district            0.0\n",
       "pincode             0.0\n",
       "age_0_5             0.0\n",
       "age_5_17            0.0\n",
       "age_18_greater      0.0\n",
       "total_enrollment    0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Missing percentage by column\n",
    "# Expected Output: Valid output for Step 55 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 55 improves trust in downstream analytics.\n",
    "\n",
    "display((eda_enroll.isnull().sum()/len(eda_enroll)*100).sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e9b186",
   "metadata": {},
   "source": [
    "#### Integrated Step 56 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ff394791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                0\n",
       "state               0\n",
       "district            0\n",
       "pincode             0\n",
       "age_0_5             0\n",
       "age_5_17            0\n",
       "age_18_greater      0\n",
       "total_enrollment    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Empty-string diagnostics\n",
    "# Expected Output: Valid output for Step 56 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 56 improves trust in downstream analytics.\n",
    "\n",
    "empty_counts = eda_enroll.apply(lambda x: (x.astype(str).str.strip()=='').sum()); display(empty_counts.sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f622e480",
   "metadata": {},
   "source": [
    "#### Integrated Step 57 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "48712338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                0\n",
       "state               0\n",
       "district            0\n",
       "pincode             0\n",
       "age_0_5             0\n",
       "age_5_17            0\n",
       "age_18_greater      0\n",
       "total_enrollment    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Combined null+empty diagnostics\n",
    "# Expected Output: Valid output for Step 57 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 57 improves trust in downstream analytics.\n",
    "\n",
    "combined_missing = eda_enroll.apply(lambda x: x.isnull().sum() + (x.astype(str).str.strip()=='').sum()); display(combined_missing.sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37829900",
   "metadata": {},
   "source": [
    "#### Integrated Step 58 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "4e4c9cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fully_empty_rows 0\n"
     ]
    }
   ],
   "source": [
    "# Aim: Fully empty row detection\n",
    "# Expected Output: Valid output for Step 58 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 58 improves trust in downstream analytics.\n",
    "\n",
    "print('fully_empty_rows', int(eda_enroll.isnull().all(axis=1).sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b224cc",
   "metadata": {},
   "source": [
    "#### Integrated Step 59 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f7fb7477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>null_count</th>\n",
       "      <th>null_pct</th>\n",
       "      <th>unique_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pincode</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>total_enrollment</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>district</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age_0_5</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>age_5_17</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>age_18_greater</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>state</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             column           dtype  null_count  null_pct  unique_count\n",
       "3           pincode           int64           0       0.0         19463\n",
       "7  total_enrollment           int64           0       0.0          1028\n",
       "2          district          object           0       0.0           985\n",
       "4           age_0_5           int64           0       0.0           671\n",
       "5          age_5_17           int64           0       0.0           624\n",
       "6    age_18_greater           int64           0       0.0           199\n",
       "0              date  datetime64[ns]           0       0.0            92\n",
       "1             state          object           0       0.0            55"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Numeric profile table\n",
    "# Expected Output: Valid output for Step 59 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 59 improves trust in downstream analytics.\n",
    "\n",
    "profile = pd.DataFrame({'column':eda_enroll.columns,'dtype':[str(eda_enroll[c].dtype) for c in eda_enroll.columns],'null_count':[int(eda_enroll[c].isna().sum()) for c in eda_enroll.columns],'null_pct':[float(eda_enroll[c].isna().mean()*100) for c in eda_enroll.columns],'unique_count':[int(eda_enroll[c].nunique(dropna=True)) for c in eda_enroll.columns]}); display(profile.sort_values(['null_pct','unique_count'], ascending=[False,False]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "4cbdda20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null_count</th>\n",
       "      <th>null_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>district</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pincode</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_0_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_5_17</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_18_greater</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                null_count  null_pct\n",
       "date                     0       0.0\n",
       "state                    0       0.0\n",
       "district                 0       0.0\n",
       "pincode                  0       0.0\n",
       "age_0_5                  0       0.0\n",
       "age_5_17                 0       0.0\n",
       "age_18_greater           0       0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Compute null profile (count + percent) for all columns.\n",
    "# Expected Output: Null summary table.\n",
    "# What You Get: Missingness ranking for quality prioritization.\n",
    "# Data Engineer Learning: Missingness must be measured both absolute and relative.\n",
    "\n",
    "null_count = data_aadhar_enrollment_full.isnull().sum()\n",
    "null_pct = (null_count / len(data_aadhar_enrollment_full)) * 100\n",
    "null_profile = pd.DataFrame({'null_count': null_count, 'null_pct': null_pct}).sort_values('null_count', ascending=False)\n",
    "\n",
    "display(null_profile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e586d7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>full_row_duplicates_before</td>\n",
       "      <td>22957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grain_duplicates_before</td>\n",
       "      <td>22957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grain_duplicates_after</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rows_before</td>\n",
       "      <td>1006029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rows_after</td>\n",
       "      <td>983072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       metric    value\n",
       "0  full_row_duplicates_before    22957\n",
       "1     grain_duplicates_before    22957\n",
       "2      grain_duplicates_after        0\n",
       "3                 rows_before  1006029\n",
       "4                  rows_after   983072"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Evaluate duplicates (full-row and grain-level) and prepare deduplicated table.\n",
    "# Expected Output: Before/after duplicate counts and new dataframe.\n",
    "# What You Get: data_aadhar_enrollment_dedup for cleaner analytics.\n",
    "# Data Engineer Learning: Keep raw and deduplicated versions separated for traceability.\n",
    "\n",
    "dup_full = int(data_aadhar_enrollment_full.duplicated().sum())\n",
    "dup_grain = int(data_aadhar_enrollment_full.duplicated(subset=natural_key).sum())\n",
    "\n",
    "data_aadhar_enrollment_dedup = data_aadhar_enrollment_full.drop_duplicates(subset=natural_key, keep='first').reset_index(drop=True)\n",
    "\n",
    "post_dup_grain = int(data_aadhar_enrollment_dedup.duplicated(subset=natural_key).sum())\n",
    "\n",
    "dup_summary = pd.DataFrame([\n",
    "    {'metric': 'full_row_duplicates_before', 'value': dup_full},\n",
    "    {'metric': 'grain_duplicates_before', 'value': dup_grain},\n",
    "    {'metric': 'grain_duplicates_after', 'value': post_dup_grain},\n",
    "    {'metric': 'rows_before', 'value': len(data_aadhar_enrollment_full)},\n",
    "    {'metric': 'rows_after', 'value': len(data_aadhar_enrollment_dedup)},\n",
    "])\n",
    "\n",
    "display(dup_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "71fc4c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with negative age counts: 0\n"
     ]
    }
   ],
   "source": [
    "# Aim: Validate numeric range constraints for measure columns.\n",
    "# Expected Output: Count of negative rows and optional suspicious values.\n",
    "# What You Get: Range validation status for age measure integrity.\n",
    "# Data Engineer Learning: Contract checks should be explicit and measurable.\n",
    "\n",
    "measure_cols = ['age_0_5', 'age_5_17', 'age_18_greater']\n",
    "neg_mask = (data_aadhar_enrollment_dedup[measure_cols] < 0).any(axis=1)\n",
    "neg_count = int(neg_mask.sum())\n",
    "print('Rows with negative age counts:', neg_count)\n",
    "if neg_count > 0:\n",
    "    display(data_aadhar_enrollment_dedup.loc[neg_mask, natural_key + measure_cols].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "d6139c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier rows (|z| > 3): 2941\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>total_enrollment</th>\n",
       "      <th>total_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02-03-2025</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>East Khasi Hills</td>\n",
       "      <td>793121</td>\n",
       "      <td>109</td>\n",
       "      <td>3.243601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Kanpur Nagar</td>\n",
       "      <td>208001</td>\n",
       "      <td>123</td>\n",
       "      <td>3.682025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Aligarh</td>\n",
       "      <td>202133</td>\n",
       "      <td>106</td>\n",
       "      <td>3.149653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Maharajganj</td>\n",
       "      <td>273164</td>\n",
       "      <td>114</td>\n",
       "      <td>3.400181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>Sitamarhi</td>\n",
       "      <td>843317</td>\n",
       "      <td>145</td>\n",
       "      <td>4.370978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>Sitamarhi</td>\n",
       "      <td>843324</td>\n",
       "      <td>269</td>\n",
       "      <td>8.254163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Ghaziabad</td>\n",
       "      <td>201102</td>\n",
       "      <td>174</td>\n",
       "      <td>5.279142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>Faridabad</td>\n",
       "      <td>121004</td>\n",
       "      <td>150</td>\n",
       "      <td>4.527558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>Madhubani</td>\n",
       "      <td>847108</td>\n",
       "      <td>160</td>\n",
       "      <td>4.840718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Gautam Buddha Nagar</td>\n",
       "      <td>201301</td>\n",
       "      <td>290</td>\n",
       "      <td>8.911800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>Katni</td>\n",
       "      <td>483501</td>\n",
       "      <td>106</td>\n",
       "      <td>3.149653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>West Delhi</td>\n",
       "      <td>110059</td>\n",
       "      <td>177</td>\n",
       "      <td>5.373090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>Purbi Champaran</td>\n",
       "      <td>845304</td>\n",
       "      <td>102</td>\n",
       "      <td>3.024389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Lucknow</td>\n",
       "      <td>226003</td>\n",
       "      <td>142</td>\n",
       "      <td>4.277030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>15-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Ghaziabad</td>\n",
       "      <td>201001</td>\n",
       "      <td>174</td>\n",
       "      <td>5.279142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>15-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Gautam Buddha Nagar</td>\n",
       "      <td>201301</td>\n",
       "      <td>199</td>\n",
       "      <td>6.062042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>15-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Ghaziabad</td>\n",
       "      <td>201102</td>\n",
       "      <td>195</td>\n",
       "      <td>5.936778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>15-03-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Marigaon</td>\n",
       "      <td>782105</td>\n",
       "      <td>182</td>\n",
       "      <td>5.529670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>15-03-2025</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>West Khasi Hills</td>\n",
       "      <td>793119</td>\n",
       "      <td>192</td>\n",
       "      <td>5.842830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>15-03-2025</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>Purbi Champaran</td>\n",
       "      <td>845303</td>\n",
       "      <td>146</td>\n",
       "      <td>4.402294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>15-03-2025</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>Sitamarhi</td>\n",
       "      <td>843324</td>\n",
       "      <td>155</td>\n",
       "      <td>4.684138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>15-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Agra</td>\n",
       "      <td>282001</td>\n",
       "      <td>182</td>\n",
       "      <td>5.529670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>15-03-2025</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>West Jaintia Hills</td>\n",
       "      <td>793150</td>\n",
       "      <td>139</td>\n",
       "      <td>4.183081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>15-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Unnao</td>\n",
       "      <td>209801</td>\n",
       "      <td>130</td>\n",
       "      <td>3.901237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>15-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Saharanpur</td>\n",
       "      <td>247001</td>\n",
       "      <td>253</td>\n",
       "      <td>7.753107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>20-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Jaunpur</td>\n",
       "      <td>222001</td>\n",
       "      <td>151</td>\n",
       "      <td>4.558874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>20-03-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Kokrajhar</td>\n",
       "      <td>783360</td>\n",
       "      <td>136</td>\n",
       "      <td>4.089133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>20-03-2025</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>Sitamarhi</td>\n",
       "      <td>843324</td>\n",
       "      <td>126</td>\n",
       "      <td>3.775973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>20-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Firozabad</td>\n",
       "      <td>283203</td>\n",
       "      <td>127</td>\n",
       "      <td>3.807289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>20-03-2025</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>Gwalior</td>\n",
       "      <td>474001</td>\n",
       "      <td>116</td>\n",
       "      <td>3.462813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date           state             district  pincode  \\\n",
       "0   02-03-2025       Meghalaya     East Khasi Hills   793121   \n",
       "2   09-03-2025   Uttar Pradesh         Kanpur Nagar   208001   \n",
       "3   09-03-2025   Uttar Pradesh              Aligarh   202133   \n",
       "10  09-03-2025   Uttar Pradesh          Maharajganj   273164   \n",
       "11  09-03-2025           Bihar            Sitamarhi   843317   \n",
       "13  09-03-2025           Bihar            Sitamarhi   843324   \n",
       "14  09-03-2025   Uttar Pradesh            Ghaziabad   201102   \n",
       "15  09-03-2025         Haryana            Faridabad   121004   \n",
       "17  09-03-2025           Bihar            Madhubani   847108   \n",
       "23  09-03-2025   Uttar Pradesh  Gautam Buddha Nagar   201301   \n",
       "27  09-03-2025  Madhya Pradesh                Katni   483501   \n",
       "28  09-03-2025           Delhi           West Delhi   110059   \n",
       "29  09-03-2025           Bihar      Purbi Champaran   845304   \n",
       "31  09-03-2025   Uttar Pradesh              Lucknow   226003   \n",
       "37  15-03-2025   Uttar Pradesh            Ghaziabad   201001   \n",
       "41  15-03-2025   Uttar Pradesh  Gautam Buddha Nagar   201301   \n",
       "44  15-03-2025   Uttar Pradesh            Ghaziabad   201102   \n",
       "45  15-03-2025           Assam             Marigaon   782105   \n",
       "46  15-03-2025       Meghalaya     West Khasi Hills   793119   \n",
       "47  15-03-2025           Bihar      Purbi Champaran   845303   \n",
       "50  15-03-2025           Bihar            Sitamarhi   843324   \n",
       "53  15-03-2025   Uttar Pradesh                 Agra   282001   \n",
       "54  15-03-2025       Meghalaya   West Jaintia Hills   793150   \n",
       "58  15-03-2025   Uttar Pradesh                Unnao   209801   \n",
       "60  15-03-2025   Uttar Pradesh           Saharanpur   247001   \n",
       "66  20-03-2025   Uttar Pradesh              Jaunpur   222001   \n",
       "71  20-03-2025           Assam            Kokrajhar   783360   \n",
       "73  20-03-2025           Bihar            Sitamarhi   843324   \n",
       "75  20-03-2025   Uttar Pradesh            Firozabad   283203   \n",
       "76  20-03-2025  Madhya Pradesh              Gwalior   474001   \n",
       "\n",
       "    total_enrollment   total_z  \n",
       "0                109  3.243601  \n",
       "2                123  3.682025  \n",
       "3                106  3.149653  \n",
       "10               114  3.400181  \n",
       "11               145  4.370978  \n",
       "13               269  8.254163  \n",
       "14               174  5.279142  \n",
       "15               150  4.527558  \n",
       "17               160  4.840718  \n",
       "23               290  8.911800  \n",
       "27               106  3.149653  \n",
       "28               177  5.373090  \n",
       "29               102  3.024389  \n",
       "31               142  4.277030  \n",
       "37               174  5.279142  \n",
       "41               199  6.062042  \n",
       "44               195  5.936778  \n",
       "45               182  5.529670  \n",
       "46               192  5.842830  \n",
       "47               146  4.402294  \n",
       "50               155  4.684138  \n",
       "53               182  5.529670  \n",
       "54               139  4.183081  \n",
       "58               130  3.901237  \n",
       "60               253  7.753107  \n",
       "66               151  4.558874  \n",
       "71               136  4.089133  \n",
       "73               126  3.775973  \n",
       "75               127  3.807289  \n",
       "76               116  3.462813  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Build total_enrollment and detect outliers using z-score.\n",
    "# Expected Output: Outlier count and sample rows.\n",
    "# What You Get: Early anomaly list for investigation.\n",
    "# Data Engineer Learning: Outliers can indicate either data issues or real events.\n",
    "\n",
    "eda_df = data_aadhar_enrollment_dedup.copy()\n",
    "eda_df['total_enrollment'] = eda_df['age_0_5'].fillna(0) + eda_df['age_5_17'].fillna(0) + eda_df['age_18_greater'].fillna(0)\n",
    "\n",
    "mu = eda_df['total_enrollment'].mean()\n",
    "sig = eda_df['total_enrollment'].std()\n",
    "eda_df['total_z'] = (eda_df['total_enrollment'] - mu) / (sig if sig and sig != 0 else np.nan)\n",
    "\n",
    "outliers = eda_df[eda_df['total_z'].abs() > 3]\n",
    "print('Outlier rows (|z| > 3):', len(outliers))\n",
    "display(outliers[natural_key + ['total_enrollment', 'total_z']].head(30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5132d461",
   "metadata": {},
   "source": [
    "### Added for Checklist Alignment: Step 4 Exact Duplicate Analysis\n",
    "This cell adds the exact duplicate-inspection and drop pattern from your checklist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b660e01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate groups (key-based): 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>age_0_5</th>\n",
       "      <th>age_5_17</th>\n",
       "      <th>age_18_greater</th>\n",
       "      <th>total_enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, state, district, pincode, age_0_5, age_5_17, age_18_greater, total_enrollment]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before key-duplicate count: 0\n",
      "After key-duplicate count : 0\n"
     ]
    }
   ],
   "source": [
    "# Aim: Run exact duplicate analysis pattern and perform explicit key-based drop.\n",
    "# Expected Output: duplicate groups preview + before/after duplicate counts.\n",
    "# What You Get: A direct checklist-style duplicate handling cell.\n",
    "# Data Engineer Learning: Separate exact duplicates from business-key duplicates before deciding drop logic.\n",
    "\n",
    "df = eda_enroll.copy() if 'eda_enroll' in globals() else data_aadhar_enrollment_full.copy()\n",
    "dup_view = df[df.duplicated(subset=['date','state','district','pincode'], keep=False)].sort_values(by=['date','state'])\n",
    "print('Duplicate groups (key-based):', len(dup_view))\n",
    "display(dup_view.head(20))\n",
    "\n",
    "before = int(df.duplicated(subset=['date','state','district','pincode']).sum())\n",
    "df_dedup_check = df.drop_duplicates(subset=['date','state','district','pincode'], keep='first').copy()\n",
    "after = int(df_dedup_check.duplicated(subset=['date','state','district','pincode']).sum())\n",
    "print('Before key-duplicate count:', before)\n",
    "print('After key-duplicate count :', after)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7d25f8",
   "metadata": {},
   "source": [
    "## STEP 5 ? Domain Validation\n",
    "Validate domain values, especially district/state naming quality.\n",
    "This is where canonical cleaning is built.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a957786",
   "metadata": {},
   "source": [
    "### Integrated 63-Step Cells For This Section\n",
    "Included steps: 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f65ea3b",
   "metadata": {},
   "source": [
    "#### Integrated Step 18 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11863dc9",
   "metadata": {},
   "source": [
    "#### Integrated Step 19 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a986ef62",
   "metadata": {},
   "source": [
    "#### Integrated Step 20 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cb83ef",
   "metadata": {},
   "source": [
    "#### Integrated Step 21 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e92ce9",
   "metadata": {},
   "source": [
    "#### Integrated Step 22 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f05efb",
   "metadata": {},
   "source": [
    "#### Integrated Step 23 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038dfc70",
   "metadata": {},
   "source": [
    "#### Integrated Step 24 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4ebde",
   "metadata": {},
   "source": [
    "#### Integrated Step 25 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af665f78",
   "metadata": {},
   "source": [
    "#### Integrated Step 26 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38831502",
   "metadata": {},
   "source": [
    "#### Integrated Step 27 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0f8ca5",
   "metadata": {},
   "source": [
    "#### Integrated Step 28 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fc6054",
   "metadata": {},
   "source": [
    "#### Integrated Step 29 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59851fca",
   "metadata": {},
   "source": [
    "#### Integrated Step 30 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e546fbf3",
   "metadata": {},
   "source": [
    "#### Integrated Step 31 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e7e3a6",
   "metadata": {},
   "source": [
    "#### Integrated Step 32 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8294ab1",
   "metadata": {},
   "source": [
    "#### Integrated Step 33 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db97a25",
   "metadata": {},
   "source": [
    "#### Integrated Step 34 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657d5a7a",
   "metadata": {},
   "source": [
    "## STEP 6 ? Column Classification\n",
    "Classify columns into dimensions/measures/time for modeling readiness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280e5945",
   "metadata": {},
   "source": [
    "### Added for Checklist Alignment: Step 6 Data Type and Format Validation\n",
    "This cell adds explicit date conversion, pincode length checks, and object-column inspection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c32521ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null dates after conversion: 0\n",
      "Pincode length distribution:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pincode</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>983072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count\n",
       "pincode        \n",
       "6        983072"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object columns: ['state', 'district']\n"
     ]
    }
   ],
   "source": [
    "# Aim: Validate date datatype, pincode format length, and object columns.\n",
    "# Expected Output: datetime conversion status, pincode length distribution, object column list.\n",
    "# What You Get: Explicit format-validation evidence for key fields.\n",
    "# Data Engineer Learning: Format checks are data contracts, not optional checks.\n",
    "\n",
    "df = eda_enroll.copy() if 'eda_enroll' in globals() else data_aadhar_enrollment_full.copy()\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce', dayfirst=True)\n",
    "print('Null dates after conversion:', int(df['date'].isna().sum()))\n",
    "\n",
    "pincode_len = df['pincode'].astype(str).str.replace(r'\\.0$', '', regex=True).str.strip().str.len().value_counts(dropna=False).sort_index()\n",
    "print('Pincode length distribution:')\n",
    "display(pincode_len.to_frame('count'))\n",
    "\n",
    "obj_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print('Object columns:', obj_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec8120e",
   "metadata": {},
   "source": [
    "## STEP 7 ? Relationship Feasibility\n",
    "Feasibility only (no modeling implementation):\n",
    "- Do Enrollment/Demographic/Biometric share keys?\n",
    "- Can they connect at date-location grain?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "66836267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table</th>\n",
       "      <th>rows</th>\n",
       "      <th>has_all_keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enrollment</td>\n",
       "      <td>983072</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>demographic</td>\n",
       "      <td>2071700</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>biometric</td>\n",
       "      <td>1861108</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         table     rows  has_all_keys\n",
       "0   enrollment   983072          True\n",
       "1  demographic  2071700          True\n",
       "2    biometric  1861108          True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Load related tables and check shared schema feasibility.\n",
    "# Expected Output: Basic table sizes and key-column existence check.\n",
    "# What You Get: Early confirmation whether joins are feasible.\n",
    "# Data Engineer Learning: Feasibility checks prevent expensive late-stage integration failures.\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "demo_path = Path(r\"C:\\Users\\Atul bhardwaj\\OneDrive\\Desktop\\coding 2 year\\IdentityLakehouse\\scripts\\EDA\\panda_eda\\data\\data_aadhar_demographic_full.csv\")\n",
    "bio_path  = Path(r\"C:\\Users\\Atul bhardwaj\\OneDrive\\Desktop\\coding 2 year\\IdentityLakehouse\\scripts\\EDA\\panda_eda\\data\\data_aadhar_biometric_full.csv\")\n",
    "\n",
    "demo_df = pd.read_csv(demo_path)\n",
    "bio_df = pd.read_csv(bio_path)\n",
    "\n",
    "required_keys = ['date', 'state', 'district', 'pincode']\n",
    "enroll_df = eda_df if 'eda_df' in globals() else data_aadhar_enrollment_full\n",
    "\n",
    "feasibility = pd.DataFrame([\n",
    "    {'table': 'enrollment',  'rows': len(enroll_df), 'has_all_keys': all(k in enroll_df.columns for k in required_keys)},\n",
    "    {'table': 'demographic', 'rows': len(demo_df),   'has_all_keys': all(k in demo_df.columns for k in required_keys)},\n",
    "    {'table': 'biometric',   'rows': len(bio_df),    'has_all_keys': all(k in bio_df.columns for k in required_keys)},\n",
    "])\n",
    "\n",
    "display(feasibility)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "234ca48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enroll_key_count</td>\n",
       "      <td>982290.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>enroll_in_demo_pct</td>\n",
       "      <td>66.3304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enroll_in_bio_pct</td>\n",
       "      <td>73.8784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               metric        value\n",
       "0    enroll_key_count  982290.0000\n",
       "1  enroll_in_demo_pct      66.3304\n",
       "2   enroll_in_bio_pct      73.8784"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Evaluate key overlap ratios from Enrollment to Demographic/Biometric.\n",
    "# Expected Output: Join coverage percentages.\n",
    "# What You Get: Quantified relationship feasibility at key grain.\n",
    "# Data Engineer Learning: Coverage metrics tell whether conformed dimensions are achievable.\n",
    "\n",
    "def prep_key(df):\n",
    "    x = df.copy()\n",
    "    x['date_key'] = pd.to_datetime(x['date'], dayfirst=True, errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "    x['state_key'] = x['state'].astype(str).str.strip().str.lower()\n",
    "    x['district_key'] = x['district'].astype(str).str.strip().str.lower()\n",
    "    x['pincode_key'] = x['pincode'].astype(str).str.replace(r'\\.0$', '', regex=True).str.strip()\n",
    "    return x[['date_key', 'state_key', 'district_key', 'pincode_key']].dropna().drop_duplicates()\n",
    "\n",
    "enroll_keys = prep_key(eda_df)\n",
    "demo_keys = prep_key(demo_df)\n",
    "bio_keys = prep_key(bio_df)\n",
    "\n",
    "enroll_not_demo = enroll_keys.merge(demo_keys, how='left', on=enroll_keys.columns.tolist(), indicator=True)\n",
    "enroll_not_demo = enroll_not_demo[enroll_not_demo['_merge'] == 'left_only']\n",
    "\n",
    "enroll_not_bio = enroll_keys.merge(bio_keys, how='left', on=enroll_keys.columns.tolist(), indicator=True)\n",
    "enroll_not_bio = enroll_not_bio[enroll_not_bio['_merge'] == 'left_only']\n",
    "\n",
    "coverage = pd.DataFrame([\n",
    "    {'metric': 'enroll_key_count', 'value': len(enroll_keys)},\n",
    "    {'metric': 'enroll_in_demo_pct', 'value': round(100 * (1 - len(enroll_not_demo)/max(len(enroll_keys),1)), 4)},\n",
    "    {'metric': 'enroll_in_bio_pct', 'value': round(100 * (1 - len(enroll_not_bio)/max(len(enroll_keys),1)), 4)},\n",
    "])\n",
    "\n",
    "display(coverage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96138f7",
   "metadata": {},
   "source": [
    "## STEP 8 ? Volume & Cardinality Analysis\n",
    "Cardinality guides partitioning and indexing strategy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5f8fd0",
   "metadata": {},
   "source": [
    "### Integrated 63-Step Cells For This Section\n",
    "Included steps: 35, 36, 37, 38, 48, 49, 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e12be48",
   "metadata": {},
   "source": [
    "#### Integrated Step 35 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "8fed20bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_unique_pincode 19463\n"
     ]
    }
   ],
   "source": [
    "# Aim: Count unique pincodes in full data\n",
    "# Expected Output: Valid output for Step 35 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 35 improves trust in downstream analytics.\n",
    "\n",
    "print('full_unique_pincode', data_aadhar_enrollment_dedup['pincode'].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52fd1f0",
   "metadata": {},
   "source": [
    "#### Integrated Step 36 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8a85be5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aim: Count unique pincodes in UP subset\n",
    "# Expected Output: Valid output for Step 36 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 36 improves trust in downstream analytics.\n",
    "\n",
    "# print('up_unique_pincode', data_aadhar_enrollment_full_uttar_pradesh['pincode'].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fb5363",
   "metadata": {},
   "source": [
    "#### Integrated Step 37 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bf51d1",
   "metadata": {},
   "source": [
    "#### Integrated Step 38 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf43d09",
   "metadata": {},
   "source": [
    "#### Integrated Step 48 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62272695",
   "metadata": {},
   "source": [
    "#### Integrated Step 49 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b465ac2",
   "metadata": {},
   "source": [
    "#### Integrated Step 50 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c96c5f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>total_enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03</td>\n",
       "      <td>16582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04</td>\n",
       "      <td>257438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05</td>\n",
       "      <td>183616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-06</td>\n",
       "      <td>215734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-07</td>\n",
       "      <td>616868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-09</td>\n",
       "      <td>1475879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-10</td>\n",
       "      <td>779617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-11</td>\n",
       "      <td>1052584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-12</td>\n",
       "      <td>733442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     month  total_enrollment\n",
       "0  2025-03             16582\n",
       "1  2025-04            257438\n",
       "2  2025-05            183616\n",
       "3  2025-06            215734\n",
       "4  2025-07            616868\n",
       "5  2025-09           1475879\n",
       "6  2025-10            779617\n",
       "7  2025-11           1052584\n",
       "8  2025-12            733442"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Monthly enrollment trend\n",
    "# Expected Output: Valid output for Step 50 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 50 improves trust in downstream analytics.\n",
    "\n",
    "monthly_trend = eda_enroll.dropna(subset=['date']).assign(month=lambda d:d['date'].dt.to_period('M').astype(str)).groupby('month', as_index=False)['total_enrollment'].sum().sort_values('month'); display(monthly_trend)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "101a3913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique states: 55\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district_nunique</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Uttar Pradesh</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Madhya Pradesh</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Bengal</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Karnataka</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maharashtra</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bihar</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andhra Pradesh</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tamil Nadu</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Odisha</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rajasthan</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Telangana</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gujarat</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chhattisgarh</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assam</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orissa</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jharkhand</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Punjab</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Haryana</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arunachal Pradesh</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jammu and Kashmir</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   district_nunique\n",
       "state                              \n",
       "Uttar Pradesh                    89\n",
       "Madhya Pradesh                   61\n",
       "West Bengal                      58\n",
       "Karnataka                        56\n",
       "Maharashtra                      53\n",
       "Bihar                            48\n",
       "Andhra Pradesh                   47\n",
       "Tamil Nadu                       46\n",
       "Odisha                           45\n",
       "Rajasthan                        43\n",
       "Telangana                        42\n",
       "Gujarat                          40\n",
       "Chhattisgarh                     40\n",
       "Assam                            38\n",
       "Orissa                           35\n",
       "Jharkhand                        35\n",
       "Punjab                           28\n",
       "Haryana                          26\n",
       "Arunachal Pradesh                25\n",
       "Jammu and Kashmir                24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique pincodes: 19463\n"
     ]
    }
   ],
   "source": [
    "# Aim: Run explicit Step 8 cardinality and distribution checks.\n",
    "# Expected Output: unique state count, district-per-state table, unique pincode count.\n",
    "# What You Get: clear dimensional cardinality evidence for schema design.\n",
    "# Data Engineer Learning: cardinality drives partitioning, indexing, and dimension sizing.\n",
    "\n",
    "df = eda_enroll.copy() if 'eda_enroll' in globals() else (eda_df.copy() if 'eda_df' in globals() else data_aadhar_enrollment_full.copy())\n",
    "\n",
    "print('Unique states:', df['state'].nunique() if 'state' in df.columns else 'state column missing')\n",
    "if all(c in df.columns for c in ['state', 'district']):\n",
    "    state_district_cardinality = df.groupby('state')['district'].nunique().sort_values(ascending=False)\n",
    "    display(state_district_cardinality.head(20).to_frame('district_nunique'))\n",
    "else:\n",
    "    print('state/district columns missing')\n",
    "\n",
    "print('Unique pincodes:', df['pincode'].nunique() if 'pincode' in df.columns else 'pincode column missing')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05057b55",
   "metadata": {},
   "source": [
    "## STEP 9 ? Data Consistency Across Tables\n",
    "Check whether Enrollment contains keys/dimensions missing in Demographic/Biometric and vice versa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5189c775",
   "metadata": {},
   "source": [
    "### Integrated 63-Step Cells For This Section\n",
    "Included steps: 39, 40, 51, 52\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb0ea81",
   "metadata": {},
   "source": [
    "#### Integrated Step 39 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac23d61",
   "metadata": {},
   "source": [
    "#### Integrated Step 40 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0bd13a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UP rows: 108066\n",
      "problem_pins: 404\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pincode</th>\n",
       "      <th>district_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>244102</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>221306</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>221308</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>224132</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>203131</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>221310</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>203141</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>274304</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>221314</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>203155</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>221401</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>203202</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>203203</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>203205</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>221402</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>221404</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>221406</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>212202</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>210504</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>224205</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>221409</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>212208</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>224234</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>224123</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>224126</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>224141</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>209308</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>221301</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>202411</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>221303</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>221304</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>211011</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>211012</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>244231</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>244241</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>244242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>244303</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>271803</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>271831</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>272148</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pincode  district_count\n",
       "1065   244102               4\n",
       "493    221306               3\n",
       "495    221308               3\n",
       "599    224132               3\n",
       "103    203131               3\n",
       "497    221310               3\n",
       "106    203141               3\n",
       "1496   274304               3\n",
       "500    221314               3\n",
       "108    203155               3\n",
       "501    221401               3\n",
       "110    203202               3\n",
       "111    203203               3\n",
       "112    203205               3\n",
       "502    221402               3\n",
       "504    221404               3\n",
       "506    221406               3\n",
       "400    212202               3\n",
       "372    210504               3\n",
       "636    224205               3\n",
       "508    221409               3\n",
       "406    212208               3\n",
       "649    224234               3\n",
       "594    224123               3\n",
       "596    224126               3\n",
       "604    224141               3\n",
       "276    209308               3\n",
       "488    221301               3\n",
       "86     202411               3\n",
       "490    221303               3\n",
       "491    221304               3\n",
       "386    211011               3\n",
       "387    211012               3\n",
       "1072   244231               3\n",
       "1075   244241               3\n",
       "1076   244242               3\n",
       "1081   244303               3\n",
       "1351   271803               3\n",
       "1358   271831               3\n",
       "1388   272148               3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Self-contained Step 39 + 40\n",
    "df = eda_df if 'eda_df' in globals() else data_aadhar_enrollment_full\n",
    "\n",
    "up_df = df[df['state'].astype(str).str.strip().str.lower().eq('uttar pradesh')].copy()\n",
    "\n",
    "pin_district_count = (\n",
    "    up_df.groupby('pincode', as_index=False)['district']\n",
    "    .nunique()\n",
    "    .rename(columns={'district': 'district_count'})\n",
    ")\n",
    "\n",
    "problem_pins = (\n",
    "    pin_district_count[pin_district_count['district_count'] > 1]\n",
    "    .sort_values('district_count', ascending=False)\n",
    ")\n",
    "\n",
    "print('UP rows:', len(up_df))\n",
    "print('problem_pins:', len(problem_pins))\n",
    "display(problem_pins.head(40))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c725694c",
   "metadata": {},
   "source": [
    "#### Integrated Step 51 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebc0bc1",
   "metadata": {},
   "source": [
    "#### Integrated Step 52 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f34c7480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enroll_not_in_demo</td>\n",
       "      <td>330733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>enroll_not_in_bio</td>\n",
       "      <td>256590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>demo_not_in_enroll</td>\n",
       "      <td>944962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bio_not_in_enroll</td>\n",
       "      <td>1038552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               metric    value\n",
       "0  enroll_not_in_demo   330733\n",
       "1   enroll_not_in_bio   256590\n",
       "2  demo_not_in_enroll   944962\n",
       "3   bio_not_in_enroll  1038552"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample enrollment keys missing in demographic:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_key</th>\n",
       "      <th>state_key</th>\n",
       "      <th>district_key</th>\n",
       "      <th>pincode_key</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-02</td>\n",
       "      <td>meghalaya</td>\n",
       "      <td>east khasi hills</td>\n",
       "      <td>793121</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>karnataka</td>\n",
       "      <td>bengaluru urban</td>\n",
       "      <td>560043</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>uttar pradesh</td>\n",
       "      <td>kanpur nagar</td>\n",
       "      <td>208001</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>uttar pradesh</td>\n",
       "      <td>aligarh</td>\n",
       "      <td>202133</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>karnataka</td>\n",
       "      <td>bengaluru urban</td>\n",
       "      <td>560016</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>bihar</td>\n",
       "      <td>sitamarhi</td>\n",
       "      <td>843331</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>bihar</td>\n",
       "      <td>sitamarhi</td>\n",
       "      <td>843330</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>uttar pradesh</td>\n",
       "      <td>bahraich</td>\n",
       "      <td>271865</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>uttar pradesh</td>\n",
       "      <td>firozabad</td>\n",
       "      <td>283204</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>bihar</td>\n",
       "      <td>purbi champaran</td>\n",
       "      <td>845418</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>uttar pradesh</td>\n",
       "      <td>maharajganj</td>\n",
       "      <td>273164</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>bihar</td>\n",
       "      <td>sitamarhi</td>\n",
       "      <td>843317</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>maharashtra</td>\n",
       "      <td>aurangabad</td>\n",
       "      <td>431001</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>bihar</td>\n",
       "      <td>sitamarhi</td>\n",
       "      <td>843324</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>uttar pradesh</td>\n",
       "      <td>ghaziabad</td>\n",
       "      <td>201102</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>haryana</td>\n",
       "      <td>faridabad</td>\n",
       "      <td>121004</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>karnataka</td>\n",
       "      <td>bengaluru urban</td>\n",
       "      <td>560068</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>bihar</td>\n",
       "      <td>madhubani</td>\n",
       "      <td>847108</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>karnataka</td>\n",
       "      <td>bengaluru urban</td>\n",
       "      <td>560032</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>rajasthan</td>\n",
       "      <td>sikar</td>\n",
       "      <td>332001</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      date_key      state_key      district_key pincode_key     _merge\n",
       "0   2025-03-02      meghalaya  east khasi hills      793121  left_only\n",
       "1   2025-03-09      karnataka   bengaluru urban      560043  left_only\n",
       "2   2025-03-09  uttar pradesh      kanpur nagar      208001  left_only\n",
       "3   2025-03-09  uttar pradesh           aligarh      202133  left_only\n",
       "4   2025-03-09      karnataka   bengaluru urban      560016  left_only\n",
       "5   2025-03-09          bihar         sitamarhi      843331  left_only\n",
       "6   2025-03-09          bihar         sitamarhi      843330  left_only\n",
       "7   2025-03-09  uttar pradesh          bahraich      271865  left_only\n",
       "8   2025-03-09  uttar pradesh         firozabad      283204  left_only\n",
       "9   2025-03-09          bihar   purbi champaran      845418  left_only\n",
       "10  2025-03-09  uttar pradesh       maharajganj      273164  left_only\n",
       "11  2025-03-09          bihar         sitamarhi      843317  left_only\n",
       "12  2025-03-09    maharashtra        aurangabad      431001  left_only\n",
       "13  2025-03-09          bihar         sitamarhi      843324  left_only\n",
       "14  2025-03-09  uttar pradesh         ghaziabad      201102  left_only\n",
       "15  2025-03-09        haryana         faridabad      121004  left_only\n",
       "16  2025-03-09      karnataka   bengaluru urban      560068  left_only\n",
       "17  2025-03-09          bihar         madhubani      847108  left_only\n",
       "18  2025-03-09      karnataka   bengaluru urban      560032  left_only\n",
       "19  2025-03-09      rajasthan             sikar      332001  left_only"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample enrollment keys missing in biometric:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_key</th>\n",
       "      <th>state_key</th>\n",
       "      <th>district_key</th>\n",
       "      <th>pincode_key</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-02</td>\n",
       "      <td>meghalaya</td>\n",
       "      <td>east khasi hills</td>\n",
       "      <td>793121</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>karnataka</td>\n",
       "      <td>bengaluru urban</td>\n",
       "      <td>560043</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>uttar pradesh</td>\n",
       "      <td>kanpur nagar</td>\n",
       "      <td>208001</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>uttar pradesh</td>\n",
       "      <td>aligarh</td>\n",
       "      <td>202133</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>karnataka</td>\n",
       "      <td>bengaluru urban</td>\n",
       "      <td>560016</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>bihar</td>\n",
       "      <td>sitamarhi</td>\n",
       "      <td>843331</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>bihar</td>\n",
       "      <td>sitamarhi</td>\n",
       "      <td>843330</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>uttar pradesh</td>\n",
       "      <td>bahraich</td>\n",
       "      <td>271865</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>uttar pradesh</td>\n",
       "      <td>firozabad</td>\n",
       "      <td>283204</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>bihar</td>\n",
       "      <td>purbi champaran</td>\n",
       "      <td>845418</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>uttar pradesh</td>\n",
       "      <td>maharajganj</td>\n",
       "      <td>273164</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>bihar</td>\n",
       "      <td>sitamarhi</td>\n",
       "      <td>843317</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>maharashtra</td>\n",
       "      <td>aurangabad</td>\n",
       "      <td>431001</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>bihar</td>\n",
       "      <td>sitamarhi</td>\n",
       "      <td>843324</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>uttar pradesh</td>\n",
       "      <td>ghaziabad</td>\n",
       "      <td>201102</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>haryana</td>\n",
       "      <td>faridabad</td>\n",
       "      <td>121004</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>karnataka</td>\n",
       "      <td>bengaluru urban</td>\n",
       "      <td>560068</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>bihar</td>\n",
       "      <td>madhubani</td>\n",
       "      <td>847108</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>karnataka</td>\n",
       "      <td>bengaluru urban</td>\n",
       "      <td>560032</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>rajasthan</td>\n",
       "      <td>sikar</td>\n",
       "      <td>332001</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      date_key      state_key      district_key pincode_key     _merge\n",
       "0   2025-03-02      meghalaya  east khasi hills      793121  left_only\n",
       "1   2025-03-09      karnataka   bengaluru urban      560043  left_only\n",
       "2   2025-03-09  uttar pradesh      kanpur nagar      208001  left_only\n",
       "3   2025-03-09  uttar pradesh           aligarh      202133  left_only\n",
       "4   2025-03-09      karnataka   bengaluru urban      560016  left_only\n",
       "5   2025-03-09          bihar         sitamarhi      843331  left_only\n",
       "6   2025-03-09          bihar         sitamarhi      843330  left_only\n",
       "7   2025-03-09  uttar pradesh          bahraich      271865  left_only\n",
       "8   2025-03-09  uttar pradesh         firozabad      283204  left_only\n",
       "9   2025-03-09          bihar   purbi champaran      845418  left_only\n",
       "10  2025-03-09  uttar pradesh       maharajganj      273164  left_only\n",
       "11  2025-03-09          bihar         sitamarhi      843317  left_only\n",
       "12  2025-03-09    maharashtra        aurangabad      431001  left_only\n",
       "13  2025-03-09          bihar         sitamarhi      843324  left_only\n",
       "14  2025-03-09  uttar pradesh         ghaziabad      201102  left_only\n",
       "15  2025-03-09        haryana         faridabad      121004  left_only\n",
       "16  2025-03-09      karnataka   bengaluru urban      560068  left_only\n",
       "17  2025-03-09          bihar         madhubani      847108  left_only\n",
       "18  2025-03-09      karnataka   bengaluru urban      560032  left_only\n",
       "19  2025-03-09      rajasthan             sikar      332001  left_only"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Compute cross-table consistency mismatches at shared grain.\n",
    "# Expected Output: mismatch counts and sample keys.\n",
    "# What You Get: Data consistency diagnostics between tables.\n",
    "# Data Engineer Learning: Cross-table consistency is mandatory before conformed modeling.\n",
    "\n",
    "grain_cols = ['date_key', 'state_key', 'district_key', 'pincode_key']\n",
    "\n",
    "demo_not_enroll = demo_keys.merge(enroll_keys, how='left', on=grain_cols, indicator=True)\n",
    "demo_not_enroll = demo_not_enroll[demo_not_enroll['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "bio_not_enroll = bio_keys.merge(enroll_keys, how='left', on=grain_cols, indicator=True)\n",
    "bio_not_enroll = bio_not_enroll[bio_not_enroll['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "consistency_summary = pd.DataFrame([\n",
    "    {'metric': 'enroll_not_in_demo', 'value': len(enroll_not_demo)},\n",
    "    {'metric': 'enroll_not_in_bio', 'value': len(enroll_not_bio)},\n",
    "    {'metric': 'demo_not_in_enroll', 'value': len(demo_not_enroll)},\n",
    "    {'metric': 'bio_not_in_enroll', 'value': len(bio_not_enroll)},\n",
    "])\n",
    "\n",
    "display(consistency_summary)\n",
    "print('Sample enrollment keys missing in demographic:')\n",
    "display(enroll_not_demo.head(20))\n",
    "print('Sample enrollment keys missing in biometric:')\n",
    "display(enroll_not_bio.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "4f42e858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved reports to: scripts\\EDA\\consistency_reports\n"
     ]
    }
   ],
   "source": [
    "# Aim: Save consistency report artifacts for auditability.\n",
    "# Expected Output: CSV files in consistency_reports folder.\n",
    "# What You Get: Reproducible artifacts for review and handoff.\n",
    "# Data Engineer Learning: Persist intermediate diagnostics as evidence, not just notebook output.\n",
    "\n",
    "report_dir = Path('scripts/EDA/consistency_reports')\n",
    "report_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "consistency_summary.to_csv(report_dir / 'cross_table_coverage_summary.csv', index=False)\n",
    "enroll_not_demo.to_csv(report_dir / 'enrollment_keys_missing_in_demographic.csv', index=False)\n",
    "enroll_not_bio.to_csv(report_dir / 'enrollment_keys_missing_in_biometric.csv', index=False)\n",
    "demo_not_enroll.to_csv(report_dir / 'demographic_keys_missing_in_enrollment.csv', index=False)\n",
    "bio_not_enroll.to_csv(report_dir / 'biometric_keys_missing_in_enrollment.csv', index=False)\n",
    "\n",
    "print('Saved reports to:', report_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8738de",
   "metadata": {},
   "source": [
    "### Added for Checklist Alignment: Step 9 Cross-Column Consistency\n",
    "This cell adds explicit pincode->district and district->state stability checks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "5182b18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pincodes mapped to >1 district: 6576\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district_nunique</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pincode</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500090</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500037</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450661</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713130</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571442</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500014</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533464</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831002</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509371</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509339</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721150</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712401</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491888</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721131</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500055</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500018</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759119</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502345</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501401</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733125</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         district_nunique\n",
       "pincode                  \n",
       "500090                  7\n",
       "500037                  6\n",
       "450661                  6\n",
       "713130                  6\n",
       "571442                  6\n",
       "500014                  6\n",
       "533464                  6\n",
       "831002                  6\n",
       "509371                  6\n",
       "509339                  6\n",
       "721150                  5\n",
       "712401                  5\n",
       "491888                  5\n",
       "721131                  5\n",
       "500055                  5\n",
       "500018                  5\n",
       "759119                  5\n",
       "502345                  5\n",
       "501401                  5\n",
       "733125                  5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Districts mapped to >1 state: 78\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_nunique</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>district</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hooghly</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kargil</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daman</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diu</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doda</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOOGHLY</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bargarh</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aurangabad</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bijapur</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cuttack</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adilabad</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kendrapara</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Badgam</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bilaspur</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dadra and Nagar Haveli</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kalahandi</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baudh</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kathua</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Howrah</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kendujhar</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        state_nunique\n",
       "district                             \n",
       "Hooghly                             4\n",
       "Kargil                              3\n",
       "Daman                               3\n",
       "Diu                                 3\n",
       "Doda                                3\n",
       "HOOGHLY                             3\n",
       "Bargarh                             2\n",
       "Aurangabad                          2\n",
       "Bijapur                             2\n",
       "Cuttack                             2\n",
       "Adilabad                            2\n",
       "Kendrapara                          2\n",
       "Badgam                              2\n",
       "Bilaspur                            2\n",
       "Dadra and Nagar Haveli              2\n",
       "Kalahandi                           2\n",
       "Baudh                               2\n",
       "Kathua                              2\n",
       "Howrah                              2\n",
       "Kendujhar                           2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Run explicit Step 9 cross-column consistency checks.\n",
    "# Expected Output: pincode->district and district->state uniqueness distributions.\n",
    "# What You Get: stability signal for geo relationships and join reliability.\n",
    "# Data Engineer Learning: unstable many-to-many geo keys create referential-quality risks.\n",
    "\n",
    "df = eda_enroll.copy() if 'eda_enroll' in globals() else (eda_df.copy() if 'eda_df' in globals() else data_aadhar_enrollment_full.copy())\n",
    "\n",
    "if all(c in df.columns for c in ['pincode', 'district']):\n",
    "    pin_to_district = df.groupby('pincode')['district'].nunique().sort_values(ascending=False)\n",
    "    print('Pincodes mapped to >1 district:', int((pin_to_district > 1).sum()))\n",
    "    display(pin_to_district.head(20).to_frame('district_nunique'))\n",
    "else:\n",
    "    print('pincode/district columns missing')\n",
    "\n",
    "if all(c in df.columns for c in ['district', 'state']):\n",
    "    district_to_state = df.groupby('district')['state'].nunique().sort_values(ascending=False)\n",
    "    print('Districts mapped to >1 state:', int((district_to_state > 1).sum()))\n",
    "    display(district_to_state.head(20).to_frame('state_nunique'))\n",
    "else:\n",
    "    print('district/state columns missing')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fead40",
   "metadata": {},
   "source": [
    "## STEP 10 ? Document Findings\n",
    "Mandatory documentation fields:\n",
    "- Grain\n",
    "- Natural Key\n",
    "- Identified issues\n",
    "- Data inconsistencies\n",
    "- Expected fixes\n",
    "- Modeling direction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "071b7116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grain</td>\n",
       "      <td>One row = enrollment counts for one date-state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natural Key</td>\n",
       "      <td>(date, state, district, pincode)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Identified issues</td>\n",
       "      <td>Full duplicates=0; Key duplicates=0; Total nul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data inconsistencies</td>\n",
       "      <td>Pincode mapped to multiple districts=6576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Expected fixes</td>\n",
       "      <td>Deduplicate on natural key, enforce contracts,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Modeling direction</td>\n",
       "      <td>Use cleaned location/date grain, conformed dim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                section                                            details\n",
       "0                 Grain  One row = enrollment counts for one date-state...\n",
       "1           Natural Key                   (date, state, district, pincode)\n",
       "2     Identified issues  Full duplicates=0; Key duplicates=0; Total nul...\n",
       "3  Data inconsistencies          Pincode mapped to multiple districts=6576\n",
       "4        Expected fixes  Deduplicate on natural key, enforce contracts,...\n",
       "5    Modeling direction  Use cleaned location/date grain, conformed dim..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Export final findings artifacts.\n",
    "# Expected Output: final_eda_findings_table.csv and final_eda_findings.md files.\n",
    "# What You Get: Persistent deliverables for portfolio/review.\n",
    "# Data Engineer Learning: Good notebooks produce durable, shareable outputs.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Use available dataframe\n",
    "df = eda_df if 'eda_df' in globals() else data_aadhar_enrollment_full\n",
    "\n",
    "# Core metrics\n",
    "dup_full = int(df.duplicated().sum())\n",
    "dup_key = int(df.duplicated(subset=['date','state','district','pincode']).sum()) if all(c in df.columns for c in ['date','state','district','pincode']) else np.nan\n",
    "null_total = int(df.isna().sum().sum())\n",
    "\n",
    "if all(c in df.columns for c in ['age_0_5','age_5_17','age_18_greater']):\n",
    "    neg_rows = int((df[['age_0_5','age_5_17','age_18_greater']] < 0).any(axis=1).sum())\n",
    "else:\n",
    "    neg_rows = np.nan\n",
    "\n",
    "# Optional pincode conflict check\n",
    "if all(c in df.columns for c in ['pincode','district']):\n",
    "    pin_conflicts = int((df.groupby('pincode')['district'].nunique() > 1).sum())\n",
    "else:\n",
    "    pin_conflicts = np.nan\n",
    "\n",
    "eda_findings_doc = pd.DataFrame([\n",
    "    {'section': 'Grain', 'details': 'One row = enrollment counts for one date-state-district-pincode combination.'},\n",
    "    {'section': 'Natural Key', 'details': '(date, state, district, pincode)'},\n",
    "    {'section': 'Identified issues', 'details': f'Full duplicates={dup_full}; Key duplicates={dup_key}; Total nulls={null_total}; Negative-age rows={neg_rows}'},\n",
    "    {'section': 'Data inconsistencies', 'details': f'Pincode mapped to multiple districts={pin_conflicts}'},\n",
    "    {'section': 'Expected fixes', 'details': 'Deduplicate on natural key, enforce contracts, standardize names using alias mapping, quarantine invalid rows.'},\n",
    "    {'section': 'Modeling direction', 'details': 'Use cleaned location/date grain, conformed dimensions, and publish only after quality checks pass.'},\n",
    "])\n",
    "\n",
    "display(eda_findings_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41fd6eb",
   "metadata": {},
   "source": [
    "## Advanced Track (After Step 10)\n",
    "These advanced analyses are optional but recommended for production-readiness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d1dfff",
   "metadata": {},
   "source": [
    "### Integrated 63-Step Cells For This Section\n",
    "Included steps: 60, 61, 62, 63\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce25a35",
   "metadata": {},
   "source": [
    "#### Integrated Step 60 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d226f653",
   "metadata": {},
   "source": [
    "#### Integrated Step 61 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c80860",
   "metadata": {},
   "source": [
    "#### Integrated Step 62 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "fbeac2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>check</th>\n",
       "      <th>failed_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>valid_date</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>valid_6_digit_pincode</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non_negative_age</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   check  failed_rows\n",
       "0             valid_date            0\n",
       "1  valid_6_digit_pincode            0\n",
       "2       non_negative_age            0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>psi_total_enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04</td>\n",
       "      <td>1.135077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05</td>\n",
       "      <td>0.976072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-06</td>\n",
       "      <td>1.215223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-07</td>\n",
       "      <td>1.534281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-09</td>\n",
       "      <td>3.903214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-10</td>\n",
       "      <td>2.320635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-11</td>\n",
       "      <td>2.409039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-12</td>\n",
       "      <td>2.201698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     month  psi_total_enrollment\n",
       "0  2025-04              1.135077\n",
       "1  2025-05              0.976072\n",
       "2  2025-06              1.215223\n",
       "3  2025-07              1.534281\n",
       "4  2025-09              3.903214\n",
       "5  2025-10              2.320635\n",
       "6  2025-11              2.409039\n",
       "7  2025-12              2.201698"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>month</th>\n",
       "      <th>total_enrollment</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>z</th>\n",
       "      <th>anomaly_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [state, month, total_enrollment, pct_change, z, anomaly_class]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aim: Data contracts, drift, freshness, anomaly classes\n",
    "# Expected Output: Valid output for Step 62 is produced.\n",
    "# What You Get: Reliable intermediate evidence for EDA completion.\n",
    "# Data Engineer Learning: Step 62 improves trust in downstream analytics.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Self-contained dataset bootstrap for Advanced block\n",
    "if 'eda_enroll' in globals():\n",
    "    pass\n",
    "elif 'eda_df' in globals():\n",
    "    eda_enroll = eda_df.copy()\n",
    "elif 'data_aadhar_enrollment_full' in globals():\n",
    "    eda_enroll = data_aadhar_enrollment_full.copy()\n",
    "else:\n",
    "    candidate_files = [\n",
    "        Path('scripts/EDA/panda_eda/data/data_aadhar_enrollment_full.csv'),\n",
    "        Path('scripts/EDA/panda_eda/eda_enrollment/data/data_aadhar_enrollment_full.csv'),\n",
    "    ]\n",
    "    src = next((f for f in candidate_files if f.exists()), None)\n",
    "    if src is None:\n",
    "        raise FileNotFoundError(f'Enrollment file not found in: {candidate_files}')\n",
    "    eda_enroll = pd.read_csv(src)\n",
    "\n",
    "if 'date' in eda_enroll.columns:\n",
    "    eda_enroll['date'] = pd.to_datetime(eda_enroll['date'], errors='coerce', dayfirst=True)\n",
    "\n",
    "for col in ['age_0_5', 'age_5_17', 'age_18_greater']:\n",
    "    if col in eda_enroll.columns:\n",
    "        eda_enroll[col] = pd.to_numeric(eda_enroll[col], errors='coerce')\n",
    "\n",
    "if 'total_enrollment' not in eda_enroll.columns and all(c in eda_enroll.columns for c in ['age_0_5', 'age_5_17', 'age_18_greater']):\n",
    "    eda_enroll['total_enrollment'] = (\n",
    "        eda_enroll['age_0_5'].fillna(0)\n",
    "        + eda_enroll['age_5_17'].fillna(0)\n",
    "        + eda_enroll['age_18_greater'].fillna(0)\n",
    "    )\n",
    "\n",
    "strict_date_ok = pd.to_datetime(eda_enroll['date'], errors='coerce').notna() if 'date' in eda_enroll.columns else pd.Series([False] * len(eda_enroll))\n",
    "pincode_ok = eda_enroll['pincode'].astype(str).str.replace(r'\\.0$', '', regex=True).str.match(r'^\\d{6}$', na=False) if 'pincode' in eda_enroll.columns else pd.Series([False] * len(eda_enroll))\n",
    "non_negative_ok = (eda_enroll[['age_0_5', 'age_5_17', 'age_18_greater']] >= 0).all(axis=1) if all(c in eda_enroll.columns for c in ['age_0_5', 'age_5_17', 'age_18_greater']) else pd.Series([False] * len(eda_enroll))\n",
    "\n",
    "contract = pd.DataFrame([\n",
    "    {'check': 'valid_date', 'failed_rows': int((~strict_date_ok).sum())},\n",
    "    {'check': 'valid_6_digit_pincode', 'failed_rows': int((~pincode_ok).sum())},\n",
    "    {'check': 'non_negative_age', 'failed_rows': int((~non_negative_ok).sum())},\n",
    "])\n",
    "\n",
    "month_vals = {}\n",
    "if 'date' in eda_enroll.columns and 'total_enrollment' in eda_enroll.columns:\n",
    "    month_vals = {\n",
    "        m: g['total_enrollment'].values\n",
    "        for m, g in eda_enroll.dropna(subset=['date']).assign(month=lambda d: d['date'].dt.to_period('M').astype(str)).groupby('month')\n",
    "    }\n",
    "\n",
    "months = sorted(month_vals.keys())\n",
    "drift_rows = []\n",
    "if len(months) >= 2:\n",
    "    base = month_vals[months[0]]\n",
    "    for m in months[1:]:\n",
    "        cur = month_vals[m]\n",
    "        q = np.linspace(0, 1, 11)\n",
    "        edges = np.unique(np.quantile(base, q))\n",
    "        if len(edges) >= 3:\n",
    "            e, _ = np.histogram(base, bins=edges)\n",
    "            a, _ = np.histogram(cur, bins=edges)\n",
    "            er = np.clip(e / max(e.sum(), 1), 1e-6, None)\n",
    "            ar = np.clip(a / max(a.sum(), 1), 1e-6, None)\n",
    "            psi = float(np.sum((ar - er) * np.log(ar / er)))\n",
    "        else:\n",
    "            psi = np.nan\n",
    "        drift_rows.append({'month': m, 'psi_total_enrollment': psi})\n",
    "\n",
    "drift = pd.DataFrame(drift_rows)\n",
    "\n",
    "# Build state_month in-place to avoid run-order dependency\n",
    "if 'date' in eda_enroll.columns and 'total_enrollment' in eda_enroll.columns and 'state' in eda_enroll.columns:\n",
    "    state_month = (\n",
    "        eda_enroll.dropna(subset=['date'])\n",
    "        .assign(month=lambda d: d['date'].dt.to_period('M').astype(str))\n",
    "        .groupby(['state', 'month'], as_index=False)['total_enrollment']\n",
    "        .sum()\n",
    "        .sort_values(['state', 'month'])\n",
    "    )\n",
    "    state_month['pct_change'] = state_month.groupby('state')['total_enrollment'].pct_change()\n",
    "    state_month['z'] = (\n",
    "        (state_month['total_enrollment'] - state_month.groupby('state')['total_enrollment'].transform('mean'))\n",
    "        / state_month.groupby('state')['total_enrollment'].transform('std').replace(0, np.nan)\n",
    "    )\n",
    "    anom = state_month.copy()\n",
    "    anom['anomaly_class'] = np.where(\n",
    "        (anom['pct_change'].abs() > 0.6) & (anom['z'].abs() > 3),\n",
    "        'likely_data_issue',\n",
    "        'normal'\n",
    "    )\n",
    "else:\n",
    "    anom = pd.DataFrame(columns=['state', 'month', 'total_enrollment', 'pct_change', 'z', 'anomaly_class'])\n",
    "\n",
    "display(contract)\n",
    "display(drift)\n",
    "display(anom[anom['anomaly_class'] != 'normal'].head(40))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fcfd48",
   "metadata": {},
   "source": [
    "#### Integrated Step 63 (from eroll.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6620b281",
   "metadata": {},
   "source": [
    "### Added for Checklist Alignment: Step 12 Trend and Time Analysis\n",
    "This cell adds the exact monthly trend flow: create month then aggregate enrollment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "dfb32876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>total_enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03</td>\n",
       "      <td>16582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04</td>\n",
       "      <td>257438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05</td>\n",
       "      <td>183616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-06</td>\n",
       "      <td>215734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-07</td>\n",
       "      <td>616868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-09</td>\n",
       "      <td>1475879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-10</td>\n",
       "      <td>779617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-11</td>\n",
       "      <td>1052584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-12</td>\n",
       "      <td>733442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     month  total_enrollment\n",
       "0  2025-03             16582\n",
       "1  2025-04            257438\n",
       "2  2025-05            183616\n",
       "3  2025-06            215734\n",
       "4  2025-07            616868\n",
       "5  2025-09           1475879\n",
       "6  2025-10            779617\n",
       "7  2025-11           1052584\n",
       "8  2025-12            733442"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total months: 9\n"
     ]
    }
   ],
   "source": [
    "# Aim: Build a simple monthly enrollment trend table.\n",
    "# Expected Output: month-wise total_enrollment series sorted by month.\n",
    "# What You Get: Clear trend baseline for growth/drop interpretation.\n",
    "# Data Engineer Learning: Time-bucketing is core for monitoring and anomaly review.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "if 'eda_enroll' in globals():\n",
    "    df = eda_enroll.copy()\n",
    "elif 'eda_df' in globals():\n",
    "    df = eda_df.copy()\n",
    "elif 'data_aadhar_enrollment_full' in globals():\n",
    "    df = data_aadhar_enrollment_full.copy()\n",
    "else:\n",
    "    raise NameError('No base dataframe found. Run Step 62 cell first.')\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce', dayfirst=True)\n",
    "if 'total_enrollment' not in df.columns and all(c in df.columns for c in ['age_0_5', 'age_5_17', 'age_18_greater']):\n",
    "    df['total_enrollment'] = df['age_0_5'].fillna(0) + df['age_5_17'].fillna(0) + df['age_18_greater'].fillna(0)\n",
    "\n",
    "df['month'] = df['date'].dt.to_period('M').astype(str)\n",
    "monthly = df.groupby('month', as_index=False)['total_enrollment'].sum().sort_values('month')\n",
    "display(monthly.head(24))\n",
    "print('Total months:', monthly['month'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "d363e440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review_df shape: (983072, 8)\n",
      "columns: 8\n"
     ]
    }
   ],
   "source": [
    "# Overall Review Cell 1/15: prepare stable review dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "if 'eda_enroll' in globals():\n",
    "    review_df = eda_enroll.copy()\n",
    "elif 'eda_df' in globals():\n",
    "    review_df = eda_df.copy()\n",
    "elif 'data_aadhar_enrollment_full' in globals():\n",
    "    review_df = data_aadhar_enrollment_full.copy()\n",
    "else:\n",
    "    candidate_files = [\n",
    "        Path('scripts/EDA/panda_eda/data/data_aadhar_enrollment_full.csv'),\n",
    "        Path('scripts/EDA/panda_eda/eda_enrollment/data/data_aadhar_enrollment_full.csv'),\n",
    "    ]\n",
    "    src = next((f for f in candidate_files if f.exists()), None)\n",
    "    if src is None:\n",
    "        raise FileNotFoundError(f'Enrollment file not found in: {candidate_files}')\n",
    "    review_df = pd.read_csv(src)\n",
    "\n",
    "if 'date' in review_df.columns:\n",
    "    review_df['date'] = pd.to_datetime(review_df['date'], errors='coerce', dayfirst=True)\n",
    "\n",
    "for c in ['age_0_5', 'age_5_17', 'age_18_greater']:\n",
    "    if c in review_df.columns:\n",
    "        review_df[c] = pd.to_numeric(review_df[c], errors='coerce')\n",
    "\n",
    "if 'total_enrollment' not in review_df.columns and all(c in review_df.columns for c in ['age_0_5', 'age_5_17', 'age_18_greater']):\n",
    "    review_df['total_enrollment'] = review_df['age_0_5'].fillna(0) + review_df['age_5_17'].fillna(0) + review_df['age_18_greater'].fillna(0)\n",
    "\n",
    "# Ensure summary_metrics exists for export cell\n",
    "summary_metrics = pd.DataFrame([\n",
    "    {'metric': 'rows', 'value': int(len(review_df))},\n",
    "    {'metric': 'columns', 'value': int(review_df.shape[1])},\n",
    "    {'metric': 'null_cells_total', 'value': int(review_df.isna().sum().sum())},\n",
    "    {'metric': 'full_row_duplicates', 'value': int(review_df.duplicated().sum())},\n",
    "])\n",
    "\n",
    "print('review_df shape:', review_df.shape)\n",
    "print('columns:', len(review_df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "1d1c4299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>non_null_count</th>\n",
       "      <th>null_count</th>\n",
       "      <th>null_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age_0_5</td>\n",
       "      <td>int64</td>\n",
       "      <td>983072</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>age_18_greater</td>\n",
       "      <td>int64</td>\n",
       "      <td>983072</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>age_5_17</td>\n",
       "      <td>int64</td>\n",
       "      <td>983072</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>983072</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>district</td>\n",
       "      <td>object</td>\n",
       "      <td>983072</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pincode</td>\n",
       "      <td>int64</td>\n",
       "      <td>983072</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>state</td>\n",
       "      <td>object</td>\n",
       "      <td>983072</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>total_enrollment</td>\n",
       "      <td>int64</td>\n",
       "      <td>983072</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             column           dtype  non_null_count  null_count  null_pct\n",
       "4           age_0_5           int64          983072           0       0.0\n",
       "6    age_18_greater           int64          983072           0       0.0\n",
       "5          age_5_17           int64          983072           0       0.0\n",
       "0              date  datetime64[ns]          983072           0       0.0\n",
       "2          district          object          983072           0       0.0\n",
       "3           pincode           int64          983072           0       0.0\n",
       "1             state          object          983072           0       0.0\n",
       "7  total_enrollment           int64          983072           0       0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Overall Review Cell 3/15: schema and datatype review\n",
    "schema_review = pd.DataFrame({\n",
    "    'column': review_df.columns,\n",
    "    'dtype': [str(review_df[c].dtype) for c in review_df.columns],\n",
    "    'non_null_count': [int(review_df[c].notna().sum()) for c in review_df.columns],\n",
    "    'null_count': [int(review_df[c].isna().sum()) for c in review_df.columns],\n",
    "    'null_pct': [round(100 * review_df[c].isna().mean(), 4) for c in review_df.columns],\n",
    "})\n",
    "display(schema_review.sort_values(['null_pct', 'column'], ascending=[False, True]).head(25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "bef7ff24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available key columns: ['date', 'state', 'district', 'pincode']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_column</th>\n",
       "      <th>null_count</th>\n",
       "      <th>null_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>state</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>district</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pincode</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key_column  null_count  null_pct\n",
       "0       date           0       0.0\n",
       "1      state           0       0.0\n",
       "2   district           0       0.0\n",
       "3    pincode           0       0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Overall Review Cell 4/15: key completeness and key-null checks\n",
    "key_cols = ['date', 'state', 'district', 'pincode']\n",
    "key_exists = [c for c in key_cols if c in review_df.columns]\n",
    "key_nulls = {c: int(review_df[c].isna().sum()) for c in key_exists}\n",
    "key_nulls_df = pd.DataFrame([{'key_column': k, 'null_count': v, 'null_pct': round(100*v/max(len(review_df),1), 4)} for k,v in key_nulls.items()])\n",
    "print('Available key columns:', key_exists)\n",
    "display(key_nulls_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "026fb5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>full_row_duplicates</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>key_duplicates_raw_key</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   metric  value\n",
       "0     full_row_duplicates      0\n",
       "1  key_duplicates_raw_key      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Overall Review Cell 5/15: duplicate audit\n",
    "if all(c in review_df.columns for c in ['date', 'state', 'district', 'pincode']):\n",
    "    dup_key = int(review_df.duplicated(subset=['date', 'state', 'district', 'pincode']).sum())\n",
    "else:\n",
    "    dup_key = np.nan\n",
    "\n",
    "dup_full = int(review_df.duplicated().sum())\n",
    "\n",
    "duplicate_audit = pd.DataFrame([\n",
    "    {'metric': 'full_row_duplicates', 'value': dup_full},\n",
    "    {'metric': 'key_duplicates_raw_key', 'value': dup_key},\n",
    "])\n",
    "display(duplicate_audit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "8588eb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>null_pct</th>\n",
       "      <th>empty_string_count</th>\n",
       "      <th>combined_missing_like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>state</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>district</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pincode</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age_0_5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>age_5_17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>age_18_greater</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>total_enrollment</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             column  null_pct  empty_string_count  combined_missing_like\n",
       "0              date       0.0                   0                      0\n",
       "1             state       0.0                   0                      0\n",
       "2          district       0.0                   0                      0\n",
       "3           pincode       0.0                   0                      0\n",
       "4           age_0_5       0.0                   0                      0\n",
       "5          age_5_17       0.0                   0                      0\n",
       "6    age_18_greater       0.0                   0                      0\n",
       "7  total_enrollment       0.0                   0                      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Overall Review Cell 6/15: missing and empty diagnostics\n",
    "null_pct = (review_df.isna().mean() * 100).round(4)\n",
    "empty_cnt = {}\n",
    "for c in review_df.columns:\n",
    "    if review_df[c].dtype == 'object':\n",
    "        empty_cnt[c] = int(review_df[c].astype(str).str.strip().eq('').sum())\n",
    "    else:\n",
    "        empty_cnt[c] = 0\n",
    "\n",
    "missing_diag = pd.DataFrame({\n",
    "    'column': review_df.columns,\n",
    "    'null_pct': [null_pct[c] for c in review_df.columns],\n",
    "    'empty_string_count': [empty_cnt[c] for c in review_df.columns],\n",
    "    'combined_missing_like': [int(review_df[c].isna().sum()) + int(empty_cnt[c]) for c in review_df.columns],\n",
    "}).sort_values(['combined_missing_like', 'null_pct'], ascending=[False, False])\n",
    "\n",
    "display(missing_diag.head(25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "950b2293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_min: 2025-03-02 00:00:00\n",
      "date_max: 2025-12-31 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_review</th>\n",
       "      <th>row_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-06</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-07</td>\n",
       "      <td>1184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-09</td>\n",
       "      <td>356059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-10</td>\n",
       "      <td>203488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-11</td>\n",
       "      <td>264183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-12</td>\n",
       "      <td>156012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  month_review  row_count\n",
       "0      2025-03        168\n",
       "1      2025-04        847\n",
       "2      2025-05        549\n",
       "3      2025-06        582\n",
       "4      2025-07       1184\n",
       "5      2025-09     356059\n",
       "6      2025-10     203488\n",
       "7      2025-11     264183\n",
       "8      2025-12     156012"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Overall Review Cell 7/15: date coverage and monthly completeness\n",
    "if 'date' in review_df.columns:\n",
    "    min_date = review_df['date'].min()\n",
    "    max_date = review_df['date'].max()\n",
    "    review_df['month_review'] = review_df['date'].dt.to_period('M').astype(str)\n",
    "    month_counts = review_df.groupby('month_review', as_index=False).size().rename(columns={'size':'row_count'})\n",
    "    print('date_min:', min_date)\n",
    "    print('date_max:', max_date)\n",
    "    display(month_counts.tail(24))\n",
    "else:\n",
    "    print('date column not available for coverage check')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "3602e470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>total_enrollment</th>\n",
       "      <th>mom_growth_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03</td>\n",
       "      <td>16582</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04</td>\n",
       "      <td>257438</td>\n",
       "      <td>1452.514775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05</td>\n",
       "      <td>183616</td>\n",
       "      <td>-28.675642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-06</td>\n",
       "      <td>215734</td>\n",
       "      <td>17.491940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-07</td>\n",
       "      <td>616868</td>\n",
       "      <td>185.939166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-09</td>\n",
       "      <td>1475879</td>\n",
       "      <td>139.253617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-10</td>\n",
       "      <td>779617</td>\n",
       "      <td>-47.176090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-11</td>\n",
       "      <td>1052584</td>\n",
       "      <td>35.012961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-12</td>\n",
       "      <td>733442</td>\n",
       "      <td>-30.319860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     month  total_enrollment  mom_growth_pct\n",
       "0  2025-03             16582             NaN\n",
       "1  2025-04            257438     1452.514775\n",
       "2  2025-05            183616      -28.675642\n",
       "3  2025-06            215734       17.491940\n",
       "4  2025-07            616868      185.939166\n",
       "5  2025-09           1475879      139.253617\n",
       "6  2025-10            779617      -47.176090\n",
       "7  2025-11           1052584       35.012961\n",
       "8  2025-12            733442      -30.319860"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Overall Review Cell 12/15: trend review with MoM growth\n",
    "if 'date' in review_df.columns and 'total_enrollment' in review_df.columns:\n",
    "    trend = review_df.dropna(subset=['date']).assign(month=lambda d: d['date'].dt.to_period('M').astype(str)).groupby('month', as_index=False)['total_enrollment'].sum().sort_values('month')\n",
    "    trend['mom_growth_pct'] = trend['total_enrollment'].pct_change() * 100\n",
    "    display(trend.tail(24))\n",
    "else:\n",
    "    print('date/total_enrollment not available for trend review')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "9d434d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>risk_id</th>\n",
       "      <th>risk</th>\n",
       "      <th>severity</th>\n",
       "      <th>check</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R1</td>\n",
       "      <td>Duplicate business keys</td>\n",
       "      <td>High</td>\n",
       "      <td>key duplicate count</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R2</td>\n",
       "      <td>Null key fields</td>\n",
       "      <td>High</td>\n",
       "      <td>nulls in date/state/district/pincode</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R3</td>\n",
       "      <td>District/state naming inconsistency</td>\n",
       "      <td>Medium</td>\n",
       "      <td>mapping coverage and mismatch rows</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R4</td>\n",
       "      <td>Pincode referential conflicts</td>\n",
       "      <td>Medium</td>\n",
       "      <td>pincode-&gt;district/state nunique</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R5</td>\n",
       "      <td>Outlier spikes</td>\n",
       "      <td>Medium</td>\n",
       "      <td>z-score and pct-change anomalies</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  risk_id                                 risk severity  \\\n",
       "0      R1              Duplicate business keys     High   \n",
       "1      R2                      Null key fields     High   \n",
       "2      R3  District/state naming inconsistency   Medium   \n",
       "3      R4        Pincode referential conflicts   Medium   \n",
       "4      R5                       Outlier spikes   Medium   \n",
       "\n",
       "                                  check status  \n",
       "0                   key duplicate count   Open  \n",
       "1  nulls in date/state/district/pincode   Open  \n",
       "2    mapping coverage and mismatch rows   Open  \n",
       "3       pincode->district/state nunique   Open  \n",
       "4      z-score and pct-change anomalies   Open  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Overall Review Cell 13/15: risk register table\n",
    "risk_rows = [\n",
    "    {'risk_id':'R1', 'risk':'Duplicate business keys', 'severity':'High', 'check':'key duplicate count', 'status':'Open'},\n",
    "    {'risk_id':'R2', 'risk':'Null key fields', 'severity':'High', 'check':'nulls in date/state/district/pincode', 'status':'Open'},\n",
    "    {'risk_id':'R3', 'risk':'District/state naming inconsistency', 'severity':'Medium', 'check':'mapping coverage and mismatch rows', 'status':'Open'},\n",
    "    {'risk_id':'R4', 'risk':'Pincode referential conflicts', 'severity':'Medium', 'check':'pincode->district/state nunique', 'status':'Open'},\n",
    "    {'risk_id':'R5', 'risk':'Outlier spikes', 'severity':'Medium', 'check':'z-score and pct-change anomalies', 'status':'Open'},\n",
    "]\n",
    "final_eda_risk_register = pd.DataFrame(risk_rows)\n",
    "display(final_eda_risk_register)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "22cbef92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rule</th>\n",
       "      <th>expected</th>\n",
       "      <th>current</th>\n",
       "      <th>pass_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natural key uniqueness</td>\n",
       "      <td>0 duplicates</td>\n",
       "      <td>See duplicate audit cell</td>\n",
       "      <td>Check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Key null checks</td>\n",
       "      <td>0 null keys</td>\n",
       "      <td>See key completeness cell</td>\n",
       "      <td>Check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No negative age counts</td>\n",
       "      <td>0 negative rows</td>\n",
       "      <td>See negative checks</td>\n",
       "      <td>Check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pincode stability</td>\n",
       "      <td>minimal conflicts</td>\n",
       "      <td>See pincode consistency cell</td>\n",
       "      <td>Check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trend stability</td>\n",
       "      <td>explainable spikes</td>\n",
       "      <td>See trend/outlier cells</td>\n",
       "      <td>Check</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rule            expected                       current  \\\n",
       "0  Natural key uniqueness        0 duplicates      See duplicate audit cell   \n",
       "1         Key null checks         0 null keys     See key completeness cell   \n",
       "2  No negative age counts     0 negative rows           See negative checks   \n",
       "3       Pincode stability   minimal conflicts  See pincode consistency cell   \n",
       "4         Trend stability  explainable spikes       See trend/outlier cells   \n",
       "\n",
       "  pass_flag  \n",
       "0     Check  \n",
       "1     Check  \n",
       "2     Check  \n",
       "3     Check  \n",
       "4     Check  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Overall Review Cell 14/15: rule status table\n",
    "rule_rows = [\n",
    "    {'rule':'Natural key uniqueness', 'expected':'0 duplicates', 'current':'See duplicate audit cell', 'pass_flag':'Check'},\n",
    "    {'rule':'Key null checks', 'expected':'0 null keys', 'current':'See key completeness cell', 'pass_flag':'Check'},\n",
    "    {'rule':'No negative age counts', 'expected':'0 negative rows', 'current':'See negative checks', 'pass_flag':'Check'},\n",
    "    {'rule':'Pincode stability', 'expected':'minimal conflicts', 'current':'See pincode consistency cell', 'pass_flag':'Check'},\n",
    "    {'rule':'Trend stability', 'expected':'explainable spikes', 'current':'See trend/outlier cells', 'pass_flag':'Check'},\n",
    "]\n",
    "final_eda_rule_status = pd.DataFrame(rule_rows)\n",
    "display(final_eda_rule_status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c9c2c7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved review outputs in: scripts\\EDA\\panda_eda\\consistency_reports\n",
      "- scripts\\EDA\\panda_eda\\consistency_reports\\overall_review_summary_metrics.csv\n",
      "- scripts\\EDA\\panda_eda\\consistency_reports\\overall_review_risk_register.csv\n",
      "- scripts\\EDA\\panda_eda\\consistency_reports\\overall_review_rule_status.csv\n",
      "- scripts\\EDA\\panda_eda\\consistency_reports\\overall_review_findings.md\n"
     ]
    }
   ],
   "source": [
    "# Overall Review Cell 15/15: export final review artifacts\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "report_dir = Path('scripts/EDA/panda_eda/consistency_reports')\n",
    "report_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Rebuild summary_metrics if missing\n",
    "if 'summary_metrics' not in globals() and 'review_df' in globals():\n",
    "    summary_metrics = pd.DataFrame([\n",
    "        {'metric': 'rows', 'value': int(len(review_df))},\n",
    "        {'metric': 'columns', 'value': int(review_df.shape[1])},\n",
    "        {'metric': 'null_cells_total', 'value': int(review_df.isna().sum().sum())},\n",
    "        {'metric': 'full_row_duplicates', 'value': int(review_df.duplicated().sum())},\n",
    "    ])\n",
    "\n",
    "if 'summary_metrics' in globals():\n",
    "    summary_metrics.to_csv(report_dir / 'overall_review_summary_metrics.csv', index=False)\n",
    "if 'final_eda_risk_register' in globals():\n",
    "    final_eda_risk_register.to_csv(report_dir / 'overall_review_risk_register.csv', index=False)\n",
    "if 'final_eda_rule_status' in globals():\n",
    "    final_eda_rule_status.to_csv(report_dir / 'overall_review_rule_status.csv', index=False)\n",
    "\n",
    "final_note = report_dir / 'overall_review_findings.md'\n",
    "lines = [\n",
    "    '# Overall Enrollment EDA Review',\n",
    "    '',\n",
    "    '- Scope: consolidated review across profiling, quality, consistency, and trend checks.',\n",
    "    '- Output files: summary metrics, risk register, rule status.',\n",
    "    '- Next: convert open checks into scheduled data quality pipeline rules.',\n",
    "]\n",
    "final_note.write_text('\\n'.join(lines), encoding='utf-8')\n",
    "\n",
    "print('Saved review outputs in:', report_dir)\n",
    "print('-', report_dir / 'overall_review_summary_metrics.csv')\n",
    "print('-', report_dir / 'overall_review_risk_register.csv')\n",
    "print('-', report_dir / 'overall_review_rule_status.csv')\n",
    "print('-', final_note)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
